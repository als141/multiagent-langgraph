# é€²åŒ–çš„ç¾¤çŸ¥èƒ½ã«åŸºã¥ãLoRAã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé›†å›£ã®å”èª¿çš„æœ€é©åŒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

> **LangGraphã«ã‚ˆã‚‹ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…**  
> ã‚²ãƒ¼ãƒ ç†è«–çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚‹å‹•çš„çŸ¥è­˜é€²åŒ–ã¨å‰µç™ºçš„å•é¡Œè§£æ±º

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![LangGraph](https://img.shields.io/badge/LangGraph-0.4.8-green.svg)](https://langchain-ai.github.io/langgraph/)
[![OpenAI](https://img.shields.io/badge/OpenAI-1.12.0-orange.svg)](https://openai.com/)
[![Research](https://img.shields.io/badge/ä¿®å£«ç ”ç©¶-2025-red.svg)](https://github.com)

## ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ä¿®å£«ç ”ç©¶ã€Œé€²åŒ–çš„ç¾¤çŸ¥èƒ½ã«åŸºã¥ãLoRAã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé›†å›£ã®å”èª¿çš„æœ€é©åŒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ã®ä¸€ç’°ã¨ã—ã¦é–‹ç™ºã•ã‚ŒãŸã€LangGraphã‚’ä½¿ç”¨ã—ãŸãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚

### ğŸš€ ç ”ç©¶ç›®æ¨™

æ§˜ã€…ãªæ€§æ ¼ã‚’æŒã¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã€ã‚²ãƒ¼ãƒ ç†è«–ã«åŸºã¥ãç›¸äº’ä½œç”¨ã‚’é€šã˜ã¦ï¼š
- å‹•çš„ãªçŸ¥è­˜é€²åŒ–ã¨å‰µç™ºçš„å•é¡Œè§£æ±ºèƒ½åŠ›ã®å®Ÿç¾
- ãƒ¡ã‚¿èªçŸ¥ãƒ»æ„æ€æ±ºå®šãƒ—ãƒ­ã‚»ã‚¹ã®é€æ˜æ€§å‘ä¸Š
- è¤‡é›‘ã§å¤šè§’çš„ãªå•é¡Œã«å¯¾ã™ã‚‹å”èª¿çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

## ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

```
multiagent-langgraph/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ multiagent_system/           # ğŸ® ã‚³ã‚¢ã‚·ã‚¹ãƒ†ãƒ 
â”‚   â”‚   â”œâ”€â”€ agents/                  # ğŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_game_agent.py           # LLMæˆ¦ç•¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
â”‚   â”‚   â”‚   â””â”€â”€ responses_api_integration.py # OpenAI Responses APIçµ±åˆ
â”‚   â”‚   â”œâ”€â”€ game_theory/             # ğŸ² ã‚²ãƒ¼ãƒ ç†è«–
â”‚   â”‚   â”‚   â”œâ”€â”€ advanced_games.py           # é«˜åº¦ã‚²ãƒ¼ãƒ å®Ÿè£…
â”‚   â”‚   â”‚   â””â”€â”€ game_strategies.py          # æˆ¦ç•¥ãƒ‘ã‚¿ãƒ¼ãƒ³
â”‚   â”‚   â”œâ”€â”€ knowledge/               # ğŸ§  çŸ¥è­˜ç®¡ç†
â”‚   â”‚   â”‚   â”œâ”€â”€ knowledge_exchange_system.py # çŸ¥è­˜äº¤æ›
â”‚   â”‚   â”‚   â””â”€â”€ agent_memory.py             # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨˜æ†¶
â”‚   â”‚   â”œâ”€â”€ reputation/              # â­ ä¿¡é ¼ãƒ»è©•åˆ¤
â”‚   â”‚   â”‚   â””â”€â”€ trust_reputation_system.py  # ä¿¡é ¼ã‚·ã‚¹ãƒ†ãƒ 
â”‚   â”‚   â”œâ”€â”€ workflows/               # ğŸ”„ LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
â”‚   â”‚   â””â”€â”€ utils/                   # ğŸ”§ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”‚   â””â”€â”€ experiments/                 # ğŸ§ª å®Ÿé¨“ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
â”‚       â”œâ”€â”€ advanced_game_experiments.py    # é«˜åº¦å®Ÿé¨“
â”‚       â”œâ”€â”€ integrated_benchmark_system.py  # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
â”‚       â””â”€â”€ responses_api_demo.py           # Responses APIãƒ‡ãƒ¢
â””â”€â”€ openai-multiagent/              # ğŸ¤ OpenAIçµ±åˆã‚·ã‚¹ãƒ†ãƒ 
```

## ğŸ® å®Ÿè£…æ¸ˆã¿æ©Ÿèƒ½

### âœ… åŸºç›¤ã‚·ã‚¹ãƒ†ãƒ 

#### 1. é«˜åº¦ãªã‚²ãƒ¼ãƒ ç†è«–ãƒ¢ãƒ‡ãƒ«
- **å…¬å…±è²¡ã‚²ãƒ¼ãƒ **: å”åŠ›ãƒ»ç«¶äº‰ãƒãƒ©ãƒ³ã‚¹ã®åˆ†æ
- **ä¿¡é ¼ã‚²ãƒ¼ãƒ **: ä¿¡é ¼é–¢ä¿‚æ§‹ç¯‰ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
- **ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³ã‚²ãƒ¼ãƒ **: ç«¶äº‰çš„è³‡æºé…åˆ†
- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å½¢æˆã‚²ãƒ¼ãƒ **: ç¤¾ä¼šãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å‹•å­¦

#### 2. LLMçµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- **OpenAI GPT-4o-mini**: è‡ªç„¶è¨€èªæ¨è«–
- **æ—¥æœ¬èªå¯¾å¿œ**: å®Œå…¨ãªæ—¥æœ¬èªæˆ¦ç•¥æ€è€ƒ
- **æ€§æ ¼ãƒ¢ãƒ‡ãƒªãƒ³ã‚°**: å¤šæ§˜ãªæ„æ€æ±ºå®šãƒ‘ã‚¿ãƒ¼ãƒ³
- **å­¦ç¿’æ©Ÿèƒ½**: çµŒé¨“ã‹ã‚‰ã®æˆ¦ç•¥é©å¿œ

#### 3. çŸ¥è­˜äº¤æ›ã‚·ã‚¹ãƒ†ãƒ 
- **çŸ¥è­˜ãƒãƒ¼ã‚±ãƒƒãƒˆ**: å¸‚å ´ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«ã‚ˆã‚‹çŸ¥è­˜å–å¼•
- **å”èª¿çš„å•é¡Œè§£æ±º**: é›†å›£çŸ¥èƒ½ã«ã‚ˆã‚‹èª²é¡Œè§£æ±º
- **å¤šæ§˜ãªäº¤æ›ãƒ—ãƒ­ãƒˆã‚³ãƒ«**: ç›´æ¥å…±æœ‰ã€ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³ã€è©•åˆ¤ãƒ™ãƒ¼ã‚¹

#### 4. ä¿¡é ¼ãƒ»è©•åˆ¤ã‚·ã‚¹ãƒ†ãƒ 
- **å¤šæ¬¡å…ƒä¿¡é ¼ãƒ¢ãƒ‡ãƒ«**: èƒ½åŠ›ãƒ»å–„æ„ãƒ»èª å®Ÿæ€§ãƒ»äºˆæ¸¬å¯èƒ½æ€§
- **å‹•çš„è©•åˆ¤æ›´æ–°**: ç›¸äº’ä½œç”¨ã«åŸºã¥ãè©•åˆ¤å¤‰åŒ–
- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¼æ’­**: ç¤¾ä¼šãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã®ä¿¡é ¼ä¼æ’­

#### 5. æœ€æ–°æŠ€è¡“çµ±åˆ
- **OpenAI Responses API**: 2025å¹´æœ€æ–°ä¼šè©±APIçµ±åˆè¨­è¨ˆ
- **ã‚¦ã‚§ãƒ–æ¤œç´¢**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æƒ…å ±å–å¾—
- **çŠ¶æ…‹æ°¸ç¶šåŒ–**: é•·æœŸè¨˜æ†¶ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç¶­æŒ

### ğŸ§ª å®Ÿé¨“ãƒ»è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 

#### åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
- **åŸºæœ¬ã‚²ãƒ¼ãƒ **: ã‚²ãƒ¼ãƒ ç†è«–åŸºç¤æ€§èƒ½è©•ä¾¡
- **çŸ¥è­˜äº¤æ›**: å”èª¿å­¦ç¿’åŠ¹æœæ¸¬å®š
- **ä¿¡é ¼æ§‹ç¯‰**: ç¤¾ä¼šé–¢ä¿‚å‹•å­¦åˆ†æ
- **çµ±åˆã‚·ã‚¹ãƒ†ãƒ **: å…¨æ©Ÿèƒ½é€£æºãƒ†ã‚¹ãƒˆ
- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: å¤§è¦æ¨¡ã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½
- **å …ç‰¢æ€§**: ç•°å¸¸çŠ¶æ³å¯¾å¿œèƒ½åŠ›

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
git clone <repository-url>
cd multiagent-langgraph

# ä»®æƒ³ç’°å¢ƒä½œæˆï¼ˆuvã‚’ä½¿ç”¨ï¼‰
uv venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv pip install -r requirements.txt
```

### 2. ç’°å¢ƒå¤‰æ•°è¨­å®š

```bash
# .envãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
echo "OPENAI_API_KEY=your_api_key_here" > .env
```

### 3. åŸºæœ¬å®Ÿé¨“å®Ÿè¡Œ

```bash
# æ—¥æœ¬èªLLMå®Ÿé¨“
python japanese_llm_experiment.py

# é«˜åº¦ã‚²ãƒ¼ãƒ å®Ÿé¨“
python src/experiments/advanced_game_experiments.py

# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
python src/experiments/integrated_benchmark_system.py
```

### 4. Responses APIãƒ‡ãƒ¢ï¼ˆå°†æ¥å®Ÿè£…ï¼‰

```bash
# Responses APIçµ±åˆãƒ‡ãƒ¢
python src/experiments/responses_api_demo.py
```

## ğŸ“Š å®Ÿè¨¼å®Ÿé¨“çµæœ

### ğŸ”¬ å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿

```
å®Ÿé¨“æˆæœï¼ˆ2025å¹´6æœˆ21æ—¥æ™‚ç‚¹ï¼‰:
- APIå‘¼ã³å‡ºã—: 10å›æˆåŠŸï¼ˆHTTP 200 OKï¼‰
- ãƒ¢ãƒ‡ãƒ«: GPT-4o-mini
- å®Ÿè¡Œæ™‚é–“: ç´„45ç§’
- è¨€èª: å®Œå…¨æ—¥æœ¬èªå¯¾å¿œ

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç‰¹æ€§:
- å¤–äº¤å®˜_ç”°ä¸­: ç¤¼å„€æ­£ã—ã„é•·æœŸé–¢ä¿‚é‡è¦–
- æ¥½è¦³ä¸»ç¾©è€…_ä½è—¤: å‰å‘ããªå…¨é¢å”åŠ›å¿—å‘  
- æˆ¦ç•¥å®¶_éˆ´æœ¨: å†·é™ãªè‡ªå·±åˆ©ç›Šè¿½æ±‚
- é©å¿œè€…_å±±ç”°: åˆ†æçš„ãªçŠ¶æ³é©å¿œ

å®šé‡çµæœ:
- å”åŠ›å¯èƒ½æ€§: 0.30-1.00
- ä¿¡é ¼å¤‰åŒ–: -0.20ï½+0.50
- æˆ¦ç•¥çš„å­¦ç¿’: å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒçµŒé¨“å­¦ç¿’
```

## ğŸ¯ ç ”ç©¶ä¾¡å€¤

### å­¦è¡“çš„è²¢çŒ®
1. **æ–°è¦æ€§**: LangGraphÃ—LLMÃ—ã‚²ãƒ¼ãƒ ç†è«–ã®çµ±åˆ
2. **å®Ÿè¨¼æ€§**: çœŸã®AIæ¨è«–ã«ã‚ˆã‚‹æˆ¦ç•¥çš„ç›¸äº’ä½œç”¨
3. **æ–¹æ³•è«–**: ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿé¨“ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
4. **å¿œç”¨æ€§**: å®Ÿä¸–ç•Œå•é¡Œã¸ã®é©ç”¨å¯èƒ½æ€§

### æŠ€è¡“çš„é©æ–°
1. **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªåˆ†æ•£ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­è¨ˆ
2. **çµ±åˆ**: ç•°ãªã‚‹AIæŠ€è¡“ã®åŠ¹æœçš„çµ„ã¿åˆã‚ã›
3. **è©•ä¾¡**: å®šé‡çš„ãƒ»å®šæ€§çš„åˆ†ææ‰‹æ³•
4. **åŠ¹ç‡æ€§**: è¨ˆç®—è³‡æºæœ€é©åŒ–æŠ€è¡“

## ğŸ› ï¸ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

### é–‹ç™ºç’°å¢ƒ
- **Python**: 3.12.9
- **ä¾å­˜ç®¡ç†**: uv
- **IDE**: VS Code + Claude
- **OS**: WSL2 Ubuntu

### ä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
```toml
[dependencies]
langgraph = "^0.4.8"
langchain = "^0.3.24"
langchain-openai = "^0.3.24"
openai = "^1.12.0"
pydantic = "^2.6.0"
numpy = "^1.26.0"
pandas = "^2.2.0"
matplotlib = "^3.8.0"
seaborn = "^0.13.0"
networkx = "^3.2.0"
scipy = "^1.12.0"
```

### ã‚¤ãƒ³ãƒ•ãƒ©
- **API**: OpenAI GPT-4o-mini
- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: JSON/CSVå½¢å¼
- **ãƒ­ã‚°**: æ§‹é€ åŒ–ãƒ­ã‚°ç®¡ç†
- **è¨­å®š**: YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

## ğŸ“ˆ ä»Šå¾Œã®é–‹ç™ºãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### Phase 1: ã‚·ã‚¹ãƒ†ãƒ æ‹¡å¼µï¼ˆçŸ­æœŸï¼‰
- [ ] **LoRAã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµ±åˆ**: ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- [ ] **å¤šè¨€èªå¯¾å¿œ**: è‹±èªãƒ»ä¸­å›½èªã§ã®å®Ÿé¨“æ‹¡å¼µ
- [ ] **é«˜åº¦åˆ†æ**: æ„Ÿæƒ…ãƒ»ãƒˆãƒ¼ãƒ³ãƒ»æ„å›³ã®è©³ç´°è§£æ
- [ ] **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å®Ÿé¨“**: ãƒ©ã‚¤ãƒ–å®Ÿé¨“ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

### Phase 2: ç ”ç©¶çµ±åˆï¼ˆä¸­æœŸï¼‰
- [ ] **é€²åŒ–çš„ç¾¤çŸ¥èƒ½**: éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ çµ±åˆ
- [ ] **åˆ†æ•£å­¦ç¿’**: è¤‡æ•°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒæ™‚å­¦ç¿’
- [ ] **è‡ªå·±çµ„ç¹”åŒ–**: éšå±¤æ§‹é€ è‡ªå‹•å½¢æˆ
- [ ] **å¤§è¦æ¨¡ä¸¦åˆ—**: ã‚¯ãƒ©ã‚¹ã‚¿ç’°å¢ƒå¯¾å¿œ

### Phase 3: å®Ÿç”¨åŒ–ï¼ˆé•·æœŸï¼‰
- [ ] **å®Ÿä¸–ç•Œå¿œç”¨**: æœ€é©åŒ–ãƒ»çµŒæ¸ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- [ ] **å­¦è¡“ç™ºè¡¨**: å›½éš›ä¼šè­°ãƒ»è«–æ–‡æŠ•ç¨¿
- [ ] **ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹**: ç ”ç©¶ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£è²¢çŒ®
- [ ] **ç”£æ¥­é€£æº**: å®Ÿç”¨ã‚·ã‚¹ãƒ†ãƒ é–‹ç™º

## ğŸ® ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨æ–¹æ³•

### ğŸ“‹ åŸºæœ¬çš„ãªä½¿ç”¨æ‰‹é †

#### 1. ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨ç’°å¢ƒç¢ºèª

```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ç§»å‹•
cd /home/als0028/work/research/multiagent-langgraph

# ä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–
source .venv/bin/activate

# ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª
cat .env
# OPENAI_API_KEY=your_api_key_here

# ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
python -c "import openai; print('OpenAI APIæ¥ç¶šOK')"
```

#### 2. åŸºæœ¬å®Ÿé¨“ã®å®Ÿè¡Œ

##### A. æ—¥æœ¬èªLLMå®Ÿé¨“ï¼ˆå®Ÿè¨¼æ¸ˆã¿ï¼‰
```bash
# åŸºæœ¬å®Ÿé¨“ï¼ˆ4ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€å›šäººã®ã‚¸ãƒ¬ãƒ³ãƒï¼‰
python japanese_llm_experiment.py

# å‡ºåŠ›ä¾‹ï¼š
# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ: å¤–äº¤å®˜_ç”°ä¸­, æ¥½è¦³ä¸»ç¾©è€…_ä½è—¤, æˆ¦ç•¥å®¶_éˆ´æœ¨, é©å¿œè€…_å±±ç”°
# APIå‘¼ã³å‡ºã—æˆåŠŸ: 10/10
# å®Ÿè¡Œæ™‚é–“: 45ç§’
# å”åŠ›å¯èƒ½æ€§: 0.30-1.00ï¼ˆå‹•çš„å¤‰åŒ–ï¼‰
```

##### B. é«˜åº¦ã‚²ãƒ¼ãƒ ç†è«–å®Ÿé¨“
```bash
# å…¬å…±è²¡ã‚²ãƒ¼ãƒ å®Ÿé¨“
python src/experiments/advanced_game_experiments.py

# ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã§ã®å®Ÿè¡Œ
python -c "
from src.experiments.advanced_game_experiments import *
config = ExperimentConfig(
    name='custom_experiment',
    num_agents=6,
    num_rounds=20,
    games_to_test=[GameType.PUBLIC_GOODS, GameType.TRUST_GAME]
)
suite = AdvancedGameExperimentSuite(config)
results = suite.run_comprehensive_experiment()
print(f'å®Ÿé¨“å®Œäº†: {len(results)}çµæœ')
"
```

##### C. åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
```bash
# å…¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ
python src/experiments/integrated_benchmark_system.py

# ç‰¹å®šãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
python -c "
from src.experiments.integrated_benchmark_system import *
import asyncio

async def run_basic_benchmark():
    benchmark = IntegratedBenchmarkSystem()
    results = await benchmark.run_benchmark_suite('basic_games')
    print(f'ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†: {len(results)}ã‚¿ã‚¹ã‚¯')
    return results

asyncio.run(run_basic_benchmark())
"
```

### ğŸ”¬ è©³ç´°å®Ÿé¨“æ‰‹é †

#### 1. å˜ä¸€ã‚²ãƒ¼ãƒ å®Ÿé¨“

```python
# å˜ä¸€ã‚²ãƒ¼ãƒ å®Ÿé¨“ã®ä¾‹
from src.multiagent_system.agents.llm_game_agent import LLMGameAgent
from src.multiagent_system.game_theory.advanced_games import PublicGoodsGame
import asyncio

async def single_game_experiment():
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
    agents = [
        LLMGameAgent("å”åŠ›è€…", {"cooperation_tendency": 0.9}),
        LLMGameAgent("ç«¶äº‰è€…", {"cooperation_tendency": 0.3}),
        LLMGameAgent("æˆ¦ç•¥å®¶", {"cooperation_tendency": 0.6})
    ]
    
    # ã‚²ãƒ¼ãƒ ä½œæˆ
    game = PublicGoodsGame(num_players=3, multiplier=2.5, endowment=100.0)
    
    # å®Ÿè¡Œ
    agent_ids = [agent.agent_id for agent in agents]
    state = game.initialize(agent_ids)
    
    # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ„æ€æ±ºå®š
    for agent in agents:
        info_set = game.get_information_set(agent.agent_id, state)
        action, reasoning = await agent.make_decision(game, state, info_set)
        print(f"{agent.agent_id}: {action.action_type} = {action.value}")
        print(f"æ¨è«–: {reasoning.decision_rationale}")
    
    return state

# å®Ÿè¡Œ
asyncio.run(single_game_experiment())
```

#### 2. çŸ¥è­˜äº¤æ›å®Ÿé¨“

```python
# çŸ¥è­˜ãƒãƒ¼ã‚±ãƒƒãƒˆå®Ÿé¨“
from src.multiagent_system.knowledge.knowledge_exchange_system import KnowledgeMarket, KnowledgeItem, KnowledgeType
from datetime import datetime

# çŸ¥è­˜ãƒãƒ¼ã‚±ãƒƒãƒˆä½œæˆ
market = KnowledgeMarket()

# çŸ¥è­˜ã‚¢ã‚¤ãƒ†ãƒ è¿½åŠ 
knowledge1 = KnowledgeItem(
    id="",
    content="å”åŠ›æˆ¦ç•¥ã¯é•·æœŸçš„ã«ã¯åˆ©ç›Šã‚’ã‚‚ãŸã‚‰ã™",
    knowledge_type=KnowledgeType.STRATEGIC,
    source_agent="expert_agent",
    created_at=datetime.now(),
    topic="cooperation_strategy",
    confidence=0.9,
    utility_value=0.8
)

market.add_knowledge(knowledge1)

# çŸ¥è­˜æ¤œç´¢
results = market.search_knowledge("å”åŠ›", KnowledgeType.STRATEGIC, "seeker_agent")
print(f"æ¤œç´¢çµæœ: {len(results)}ä»¶")
for result in results:
    print(f"- {result.content} (ä¿¡é ¼åº¦: {result.confidence})")
```

#### 3. ä¿¡é ¼ãƒ»è©•åˆ¤ã‚·ã‚¹ãƒ†ãƒ å®Ÿé¨“

```python
# ä¿¡é ¼ã‚·ã‚¹ãƒ†ãƒ å®Ÿé¨“
from src.multiagent_system.reputation.trust_reputation_system import TrustReputationSystem, InteractionType

# ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
trust_system = TrustReputationSystem()

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç™»éŒ²
agents = ["Alice", "Bob", "Charlie"]
for agent in agents:
    trust_system.register_agent(agent)

# ç›¸äº’ä½œç”¨è¨˜éŒ²
interaction_id = trust_system.record_interaction(
    agent_a="Alice",
    agent_b="Bob", 
    interaction_type=InteractionType.COOPERATION,
    outcome="success",
    details={"payoff_a": 10, "payoff_b": 10},
    satisfaction_a=0.9,
    satisfaction_b=0.8,
    context="public_goods_game"
)

# ä¿¡é ¼ã‚¹ã‚³ã‚¢å–å¾—
trust_score = trust_system.get_trust_score("Alice", "Bob")
print(f"Aliceâ†’Bobã®ä¿¡é ¼åº¦: {trust_score.overall:.3f}")

# è©•åˆ¤ã‚¹ã‚³ã‚¢å–å¾—
reputation = trust_system.get_reputation_score("Bob")
print(f"Bobã®è©•åˆ¤: {reputation:.3f}")
```

### ğŸ“Š å®Ÿé¨“çµæœã®åˆ†æ

#### 1. çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª

```bash
# å®Ÿé¨“çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
ls results/

# å…·ä½“çš„ãªçµæœãƒ•ã‚¡ã‚¤ãƒ«
ls results/advanced_experiments/
ls results/benchmarks/
ls results/sample_advanced/
```

#### 2. çµæœãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å¯è¦–åŒ–

```python
# å®Ÿé¨“çµæœã®åˆ†æ
import json
import pandas as pd
import matplotlib.pyplot as plt

# å®Ÿé¨“çµæœèª­ã¿è¾¼ã¿
with open('results/advanced_experiments/public_goods_results.json', 'r') as f:
    results = json.load(f)

# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ–
outcomes = results['outcomes']
df = pd.DataFrame([
    {
        'round': i,
        'social_welfare': outcome['social_welfare'],
        'cooperation_level': outcome['cooperation_level'],
        'fairness_index': outcome['fairness_index']
    }
    for i, outcome in enumerate(outcomes)
])

# å¯è¦–åŒ–
plt.figure(figsize=(12, 4))

plt.subplot(131)
plt.plot(df['round'], df['social_welfare'])
plt.title('ç¤¾ä¼šåšç”Ÿã®æ¨ç§»')
plt.xlabel('ãƒ©ã‚¦ãƒ³ãƒ‰')
plt.ylabel('ç¤¾ä¼šåšç”Ÿ')

plt.subplot(132) 
plt.plot(df['round'], df['cooperation_level'])
plt.title('å”åŠ›ãƒ¬ãƒ™ãƒ«ã®æ¨ç§»')
plt.xlabel('ãƒ©ã‚¦ãƒ³ãƒ‰')
plt.ylabel('å”åŠ›ãƒ¬ãƒ™ãƒ«')

plt.subplot(133)
plt.plot(df['round'], df['fairness_index'])
plt.title('å…¬å¹³æ€§æŒ‡æ•°ã®æ¨ç§»')
plt.xlabel('ãƒ©ã‚¦ãƒ³ãƒ‰')
plt.ylabel('å…¬å¹³æ€§æŒ‡æ•°')

plt.tight_layout()
plt.savefig('results/analysis_summary.png')
plt.show()
```

### ğŸ”§ ã‚«ã‚¹ã‚¿ãƒ å®Ÿé¨“ã®ä½œæˆ

#### 1. ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ€§æ ¼ã®å®šç¾©

```python
# ã‚«ã‚¹ã‚¿ãƒ æ€§æ ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
custom_personalities = {
    "æ…é‡ãªå”åŠ›è€…": {
        "cooperation_tendency": 0.8,
        "risk_tolerance": 0.2,
        "trust_propensity": 0.7,
        "rationality": 0.9,
        "learning_speed": 0.3,
        "communication_style": "cautious",
        "description": "æ…é‡ã ãŒå”åŠ›çš„ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
    },
    "ç©æ¥µçš„ç«¶äº‰è€…": {
        "cooperation_tendency": 0.2,
        "risk_tolerance": 0.9,
        "trust_propensity": 0.3,
        "rationality": 0.8,
        "learning_speed": 0.7,
        "communication_style": "aggressive", 
        "description": "ç©æ¥µçš„ã§ç«¶äº‰çš„ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
    },
    "ãƒãƒ©ãƒ³ã‚¹å‹å­¦ç¿’è€…": {
        "cooperation_tendency": 0.5,
        "risk_tolerance": 0.5,
        "trust_propensity": 0.5,
        "rationality": 0.9,
        "learning_speed": 0.8,
        "communication_style": "adaptive",
        "description": "çŠ¶æ³ã«å¿œã˜ã¦å­¦ç¿’ãƒ»é©å¿œã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
    }
}

# ä½¿ç”¨ä¾‹
from src.multiagent_system.agents.llm_game_agent import LLMGameAgent

agents = [
    LLMGameAgent("agent_1", custom_personalities["æ…é‡ãªå”åŠ›è€…"]),
    LLMGameAgent("agent_2", custom_personalities["ç©æ¥µçš„ç«¶äº‰è€…"]),
    LLMGameAgent("agent_3", custom_personalities["ãƒãƒ©ãƒ³ã‚¹å‹å­¦ç¿’è€…"])
]
```

#### 2. å®Ÿé¨“è¨­å®šã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

```python
# é«˜åº¦ãªå®Ÿé¨“è¨­å®š
from src.experiments.advanced_game_experiments import ExperimentConfig, AdvancedGameExperimentSuite

# ã‚«ã‚¹ã‚¿ãƒ å®Ÿé¨“è¨­å®š
config = ExperimentConfig(
    name="custom_cooperation_study",
    num_agents=8,
    num_rounds=50,
    num_trials=10,
    games_to_test=[
        GameType.PUBLIC_GOODS,
        GameType.TRUST_GAME,
        GameType.NETWORK_FORMATION
    ],
    agent_personalities=list(custom_personalities.values()),
    output_dir="results/custom_cooperation",
    save_detailed_logs=True,
    visualize_results=True
)

# å®Ÿé¨“å®Ÿè¡Œ
suite = AdvancedGameExperimentSuite(config)
results = suite.run_comprehensive_experiment()
```

### ğŸ” ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ

#### åˆ©ç”¨å¯èƒ½ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¤ãƒ¼ãƒˆ

```python
# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æƒ…å ±ç¢ºèª
from src.experiments.integrated_benchmark_system import IntegratedBenchmarkSystem

benchmark = IntegratedBenchmarkSystem()
summary = benchmark.get_benchmark_summary()

print("åˆ©ç”¨å¯èƒ½ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¤ãƒ¼ãƒˆ:")
for suite_name, details in summary["suite_details"].items():
    print(f"- {suite_name}: {details['description']}")
    print(f"  ã‚¿ã‚¹ã‚¯æ•°: {details['task_count']}")
    print(f"  äºˆæƒ³æ™‚é–“: {details['estimated_time_minutes']}åˆ†")
    print(f"  è¤‡é›‘åº¦: {details['complexity_range']}")
```

#### ç‰¹å®šãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å®Ÿè¡Œ

```python
# åŸºæœ¬ã‚²ãƒ¼ãƒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
import asyncio

async def run_game_benchmark():
    benchmark = IntegratedBenchmarkSystem()
    results = await benchmark.run_benchmark_suite("basic_games")
    
    print(f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ:")
    for result in results:
        status = "æˆåŠŸ" if result.success else "å¤±æ•—"
        print(f"- {result.task_id}: {status} (ã‚¹ã‚³ã‚¢: {result.score:.1f})")
    
    return results

# å®Ÿè¡Œ
results = asyncio.run(run_game_benchmark())
```

### ğŸ“ˆ é«˜åº¦ãªåˆ†ææ‰‹æ³•

#### 1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¡Œå‹•åˆ†æ

```python
# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¡Œå‹•ã®è©³ç´°åˆ†æ
import seaborn as sns
import numpy as np

def analyze_agent_behavior(experiment_results):
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ¥ã®è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    agent_data = []
    
    for result in experiment_results:
        for agent_id, performance in result.agent_performances.items():
            agent_data.append({
                'agent_id': agent_id,
                'cooperation_rate': performance.get('cooperation_rate', 0),
                'average_payoff': performance.get('average_payoff', 0),
                'trust_given': performance.get('trust_given', 0),
                'trust_received': performance.get('trust_received', 0)
            })
    
    df = pd.DataFrame(agent_data)
    
    # ç›¸é–¢åˆ†æ
    correlation_matrix = df[['cooperation_rate', 'average_payoff', 'trust_given', 'trust_received']].corr()
    
    plt.figure(figsize=(10, 8))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
    plt.title('ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¡Œå‹•æŒ‡æ¨™ã®ç›¸é–¢é–¢ä¿‚')
    plt.tight_layout()
    plt.savefig('results/agent_behavior_correlation.png')
    plt.show()
    
    return df, correlation_matrix

# ä½¿ç”¨ä¾‹
# df, corr = analyze_agent_behavior(experiment_results)
```

#### 2. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ

```python
# ä¿¡é ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å¯è¦–åŒ–
import networkx as nx

def visualize_trust_network(trust_system):
    # ä¿¡é ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å–å¾—
    network_metrics = trust_system.get_trust_network_metrics()
    G = trust_system.trust_network
    
    plt.figure(figsize=(12, 8))
    
    # ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚ºã‚’è©•åˆ¤ã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ã¦è¨­å®š
    node_sizes = []
    for node in G.nodes():
        reputation = trust_system.get_reputation_score(node)
        node_sizes.append(reputation * 1000)
    
    # ã‚¨ãƒƒã‚¸ã®å¤ªã•ã‚’ä¿¡é ¼åº¦ã«åŸºã¥ã„ã¦è¨­å®š
    edge_weights = []
    for u, v, data in G.edges(data=True):
        edge_weights.append(data.get('weight', 0.5) * 5)
    
    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æç”»
    pos = nx.spring_layout(G)
    nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color='lightblue', alpha=0.7)
    nx.draw_networkx_labels(G, pos, font_size=8)
    nx.draw_networkx_edges(G, pos, width=edge_weights, alpha=0.6, edge_color='gray')
    
    plt.title(f'ä¿¡é ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ (å¯†åº¦: {network_metrics.get("network_density", 0):.3f})')
    plt.axis('off')
    plt.tight_layout()
    plt.savefig('results/trust_network.png')
    plt.show()

# ä½¿ç”¨ä¾‹
# visualize_trust_network(trust_system)
```

### ğŸ§ª å®Ÿé¨“ã®å®Ÿè¡Œæ–¹æ³•

#### åŸºæœ¬ã‚²ãƒ¼ãƒ å®Ÿé¨“

```python
# å…¬å…±è²¡ã‚²ãƒ¼ãƒ 
from src.experiments.advanced_game_experiments import *

config = ExperimentConfig(
    name="public_goods_experiment",
    num_agents=4,
    num_rounds=10,
    games_to_test=[GameType.PUBLIC_GOODS]
)

suite = AdvancedGameExperimentSuite(config)
results = suite.run_comprehensive_experiment()
```

#### ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ

```python
# åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
from src.experiments.integrated_benchmark_system import *

benchmark = IntegratedBenchmarkSystem()
results = await benchmark.run_benchmark_suite("basic_games")
```

#### ã‚«ã‚¹ã‚¿ãƒ å®Ÿé¨“

```python
# ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿé¨“
agents = [
    LLMGameAgent("agent_1", custom_personality_1),
    LLMGameAgent("agent_2", custom_personality_2)
]

game = PublicGoodsGame(num_players=2, multiplier=2.5)
outcome = await run_custom_experiment(game, agents)
```

## ğŸ“‹ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¤ãƒ¼ãƒˆ

### åˆ©ç”¨å¯èƒ½ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

1. **basic_games**: åŸºæœ¬çš„ãªã‚²ãƒ¼ãƒ ç†è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
2. **knowledge_exchange**: çŸ¥è­˜äº¤æ›ã‚·ã‚¹ãƒ†ãƒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯  
3. **trust_reputation**: ä¿¡é ¼ãƒ»è©•åˆ¤ã‚·ã‚¹ãƒ†ãƒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
4. **integrated_systems**: çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
5. **scalability**: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
6. **robustness**: å …ç‰¢æ€§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

### æ€§èƒ½è©•ä¾¡æŒ‡æ¨™

- **å”åŠ›ãƒ¬ãƒ™ãƒ«**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®å”åŠ›åº¦
- **ç¤¾ä¼šåšç”Ÿ**: å…¨ä½“ã®åˆ©ç›Šæœ€å¤§åŒ–
- **å…¬å¹³æ€§æŒ‡æ•°**: åˆ©ç›Šåˆ†é…ã®å…¬å¹³æ€§
- **ä¿¡é ¼åº¦**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®ä¿¡é ¼é–¢ä¿‚
- **çŸ¥è­˜åˆ©ç”¨ç‡**: çŸ¥è­˜äº¤æ›ã®åŠ¹æœ
- **é©å¿œé€Ÿåº¦**: ç’°å¢ƒå¤‰åŒ–ã¸ã®å¯¾å¿œ

## ğŸ”¬ ç ”ç©¶æ´»ç”¨ä¾‹

### è«–æ–‡ãƒ»ç™ºè¡¨ã§ã®åˆ©ç”¨

```bibtex
@mastersthesis{multiagent_lora_optimization,
  title={é€²åŒ–çš„ç¾¤çŸ¥èƒ½ã«åŸºã¥ãLoRAã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé›†å›£ã®å”èª¿çš„æœ€é©åŒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯},
  author={Your Name},
  school={Your University},
  year={2025},
  note={LangGraphã«ã‚ˆã‚‹ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…}
}
```

### å†ç¾å®Ÿé¨“

```bash
# è«–æ–‡å®Ÿé¨“ã®å†ç¾
python reproduce_paper_experiments.py --config paper_config.yaml

# çµæœæ¯”è¼ƒ
python compare_results.py --baseline paper_results.json --current new_results.json
```

## ğŸ¤ ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

### é–‹ç™ºã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³

1. **ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«**: PEP 8æº–æ‹ 
2. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: æ—¥æœ¬èªã‚³ãƒ¡ãƒ³ãƒˆæ¨å¥¨
3. **ãƒ†ã‚¹ãƒˆ**: pytestä½¿ç”¨
4. **ãƒ­ã‚°**: æ§‹é€ åŒ–ãƒ­ã‚°å¿…é ˆ

### Issueãƒ»PRæ­“è¿é …ç›®

- æ–°ã—ã„ã‚²ãƒ¼ãƒ ç†è«–ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…
- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæˆ¦ç•¥ã®æ”¹è‰¯
- å®Ÿé¨“è©•ä¾¡æŒ‡æ¨™ã®è¿½åŠ 
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå……å®Ÿ

## ğŸ“ ã‚µãƒãƒ¼ãƒˆãƒ»é€£çµ¡

### ç ”ç©¶é–¢é€£

- **ä¿®å£«è«–æ–‡**: ã€Œé€²åŒ–çš„ç¾¤çŸ¥èƒ½ã«åŸºã¥ãLoRAã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé›†å›£ã®å”èª¿çš„æœ€é©åŒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€
- **æŒ‡å°æ•™å“¡**: [æŒ‡å°æ•™å“¡å]
- **ç ”ç©¶å®¤**: [ç ”ç©¶å®¤å]

### æŠ€è¡“ã‚µãƒãƒ¼ãƒˆ

- **Issues**: GitHub Issuesæ´»ç”¨
- **ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³**: GitHub Discussions
- **ãƒ¡ãƒ¼ãƒ«**: [é€£çµ¡å…ˆãƒ¡ãƒ¼ãƒ«]

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ä¿®å£«ç ”ç©¶ã®ä¸€ç’°ã¨ã—ã¦é–‹ç™ºã•ã‚Œã¦ãŠã‚Šã€å­¦è¡“åˆ©ç”¨ã«ã¤ã„ã¦ã¯è‡ªç”±ã«ã”æ´»ç”¨ã„ãŸã ã‘ã¾ã™ã€‚å•†ç”¨åˆ©ç”¨ã«ã¤ã„ã¦ã¯è¦ç›¸è«‡ã§ã™ã€‚

## ğŸ™ è¬è¾

æœ¬ç ”ç©¶ã®å®Ÿç¾ã«ã‚ãŸã‚Šã€ä»¥ä¸‹ã®æŠ€è¡“ãƒ»ãƒªã‚½ãƒ¼ã‚¹ã‚’æ´»ç”¨ã•ã›ã¦ã„ãŸã ãã¾ã—ãŸï¼š

- **LangGraph**: LangChainç¤¾ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç®¡ç†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- **OpenAI API**: GPT-4o-miniã«ã‚ˆã‚‹è‡ªç„¶è¨€èªå‡¦ç†
- **Claude Code**: é–‹ç™ºæ”¯æ´AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ

---

**æœ€çµ‚æ›´æ–°**: 2025å¹´6æœˆ21æ—¥
**é–‹ç™ºçŠ¶æ³**: åŸºç›¤ã‚·ã‚¹ãƒ†ãƒ å®Œæˆã€å®Ÿé¨“å®Ÿè¨¼æ¸ˆã¿ã€æ‹¡å¼µé–‹ç™ºæº–å‚™å®Œäº†