# ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨æ–¹æ³• - å®Œå…¨ã‚¬ã‚¤ãƒ‰

## ğŸ“‹ ç›®æ¬¡

1. [ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦](#ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦)
2. [ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—](#ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—)
3. [åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•](#åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•)
4. [é«˜åº¦ãªå®Ÿé¨“æ‰‹é †](#é«˜åº¦ãªå®Ÿé¨“æ‰‹é †)
5. [çµæœåˆ†ææ–¹æ³•](#çµæœåˆ†ææ–¹æ³•)
6. [ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ–¹æ³•](#ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ–¹æ³•)
7. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)

## ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦

æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¯ã€LangGraphã‚’åŸºç›¤ã¨ã—ãŸé«˜åº¦ãªãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚²ãƒ¼ãƒ ç†è«–å®Ÿé¨“ç’°å¢ƒã§ã™ã€‚ä»¥ä¸‹ã®ä¸»è¦æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š

### ğŸ¯ ä¸»è¦æ©Ÿèƒ½
- **é«˜åº¦ã‚²ãƒ¼ãƒ ç†è«–**: å…¬å…±è²¡ã€ä¿¡é ¼ã€ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å½¢æˆã‚²ãƒ¼ãƒ 
- **LLMçµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**: OpenAI GPT-4o-miniã«ã‚ˆã‚‹è‡ªç„¶è¨€èªæ¨è«–
- **çŸ¥è­˜äº¤æ›ã‚·ã‚¹ãƒ†ãƒ **: ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ™ãƒ¼ã‚¹ã®çŸ¥è­˜å–å¼•ãƒ»å”èª¿å•é¡Œè§£æ±º
- **ä¿¡é ¼ãƒ»è©•åˆ¤ã‚·ã‚¹ãƒ†ãƒ **: å¤šæ¬¡å…ƒä¿¡é ¼ãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ
- **åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯**: 6ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¤ãƒ¼ãƒˆã«ã‚ˆã‚‹æ€§èƒ½è©•ä¾¡

### ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

```
src/
â”œâ”€â”€ multiagent_system/              # ã‚³ã‚¢ã‚·ã‚¹ãƒ†ãƒ 
â”‚   â”œâ”€â”€ agents/                     # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…
â”‚   â”‚   â”œâ”€â”€ llm_game_agent.py      # LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
â”‚   â”‚   â””â”€â”€ responses_api_integration.py # Responses APIçµ±åˆ
â”‚   â”œâ”€â”€ game_theory/               # ã‚²ãƒ¼ãƒ ç†è«–
â”‚   â”‚   â””â”€â”€ advanced_games.py      # é«˜åº¦ã‚²ãƒ¼ãƒ å®Ÿè£…
â”‚   â”œâ”€â”€ knowledge/                 # çŸ¥è­˜ç®¡ç†
â”‚   â”‚   â””â”€â”€ knowledge_exchange_system.py
â”‚   â”œâ”€â”€ reputation/                # ä¿¡é ¼ãƒ»è©•åˆ¤
â”‚   â”‚   â””â”€â”€ trust_reputation_system.py
â”‚   â””â”€â”€ workflows/                 # LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
â””â”€â”€ experiments/                   # å®Ÿé¨“ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
    â”œâ”€â”€ advanced_game_experiments.py
    â”œâ”€â”€ integrated_benchmark_system.py
    â””â”€â”€ responses_api_demo.py
```

## ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 1. åŸºæœ¬ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ç§»å‹•
cd /home/als0028/work/research/multiagent-langgraph

# 2. ä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–
source .venv/bin/activate

# 3. ä¾å­˜é–¢ä¿‚ã®ç¢ºèª
pip list | grep -E "(openai|langgraph|langchain)"

# 4. ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
echo "OPENAI_API_KEY=your_api_key_here" > .env

# 5. ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
python -c "
import openai
import sys
try:
    client = openai.OpenAI()
    print('âœ… OpenAI APIæ¥ç¶šOK')
except Exception as e:
    print(f'âŒ OpenAI APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}')
    sys.exit(1)
"
```

### 2. å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèª

```python
# ã‚·ã‚¹ãƒ†ãƒ å‹•ä½œç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ
def check_system_dependencies():
    required_packages = [
        'openai', 'langgraph', 'langchain', 'pydantic',
        'numpy', 'pandas', 'matplotlib', 'seaborn', 'networkx'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ… {package}: OK")
        except ImportError:
            print(f"âŒ {package}: Missing")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nä¸è¶³ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸: {missing_packages}")
        print("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install " + " ".join(missing_packages))
    else:
        print("\nğŸ‰ å…¨ä¾å­˜é–¢ä¿‚OK")

check_system_dependencies()
```

## åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

### 1. å®Ÿè¨¼æ¸ˆã¿æ—¥æœ¬èªLLMå®Ÿé¨“

```bash
# æœ€ã‚‚ç°¡å˜ãªé–‹å§‹æ–¹æ³•
python japanese_llm_experiment.py
```

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›:**
```
ğŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆä¸­...
âœ… å¤–äº¤å®˜_ç”°ä¸­: å”åŠ›çš„ãƒ»é•·æœŸé–¢ä¿‚é‡è¦–
âœ… æ¥½è¦³ä¸»ç¾©è€…_ä½è—¤: å‰å‘ããƒ»å…¨é¢å”åŠ›
âœ… æˆ¦ç•¥å®¶_éˆ´æœ¨: å†·é™ãƒ»è‡ªå·±åˆ©ç›Šè¿½æ±‚
âœ… é©å¿œè€…_å±±ç”°: åˆ†æçš„ãƒ»çŠ¶æ³é©å¿œ

ğŸ® ã‚²ãƒ¼ãƒ é–‹å§‹...
ğŸ“Š APIå‘¼ã³å‡ºã—: 10/10æˆåŠŸ
â±ï¸  å®Ÿè¡Œæ™‚é–“: ç´„45ç§’
ğŸ“ˆ å”åŠ›å¯èƒ½æ€§: 0.30-1.00ï¼ˆå‹•çš„å¤‰åŒ–ï¼‰
ğŸ’­ æˆ¦ç•¥å­¦ç¿’: å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå­¦ç¿’ç¢ºèª
```

### 2. é«˜åº¦ã‚²ãƒ¼ãƒ ç†è«–å®Ÿé¨“

#### A. å…¬å…±è²¡ã‚²ãƒ¼ãƒ å®Ÿé¨“

```python
# single_public_goods_experiment.py ã¨ã—ã¦ä¿å­˜
import asyncio
from src.multiagent_system.agents.llm_game_agent import LLMGameAgent
from src.multiagent_system.game_theory.advanced_games import PublicGoodsGame

async def run_public_goods_experiment():
    print("ğŸ¯ å…¬å…±è²¡ã‚²ãƒ¼ãƒ å®Ÿé¨“é–‹å§‹")
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
    agents = [
        LLMGameAgent("å”åŠ›çš„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", {
            "cooperation_tendency": 0.9,
            "risk_tolerance": 0.3,
            "description": "å”åŠ›ã‚’é‡è¦–ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
        }),
        LLMGameAgent("ç«¶äº‰çš„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", {
            "cooperation_tendency": 0.2,
            "risk_tolerance": 0.8,
            "description": "è‡ªå·±åˆ©ç›Šã‚’è¿½æ±‚ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
        }),
        LLMGameAgent("ãƒãƒ©ãƒ³ã‚¹å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", {
            "cooperation_tendency": 0.6,
            "risk_tolerance": 0.5,
            "description": "çŠ¶æ³ã«å¿œã˜ã¦åˆ¤æ–­ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
        })
    ]
    
    # ã‚²ãƒ¼ãƒ è¨­å®š
    game = PublicGoodsGame(
        num_players=3,
        multiplier=2.5,
        endowment=100.0,
        enable_punishment=True
    )
    
    # ã‚²ãƒ¼ãƒ åˆæœŸåŒ–
    agent_ids = [agent.agent_id for agent in agents]
    state = game.initialize(agent_ids)
    
    print(f"ğŸ’° åˆæœŸè³‡é‡‘: {game.endowment}")
    print(f"ğŸ”¢ ä¹—æ•°: {game.multiplier}")
    print(f"âš–ï¸  ç½°å‰‡ã‚·ã‚¹ãƒ†ãƒ : {'æœ‰åŠ¹' if game.enable_punishment else 'ç„¡åŠ¹'}")
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ„æ€æ±ºå®š
    decisions = {}
    for agent in agents:
        print(f"\nğŸ¤” {agent.agent_id}ã®æ€è€ƒä¸­...")
        
        info_set = game.get_information_set(agent.agent_id, state)
        action, reasoning = await agent.make_decision(game, state, info_set)
        
        decisions[agent.agent_id] = {
            'action': action,
            'reasoning': reasoning
        }
        
        print(f"ğŸ’¡ æ±ºå®š: {action.action_type} = {action.value}")
        print(f"ğŸ§  æ¨è«–: {reasoning.decision_rationale[:100]}...")
        
        # è¡Œå‹•é©ç”¨
        if game.is_valid_action(action, state):
            state = game.apply_action(action, state)
    
    # çµæœè¨ˆç®—
    payoffs = game.calculate_payoffs(state)
    
    print(f"\nğŸ“Š å®Ÿé¨“çµæœ:")
    total_contribution = sum(state.public_info.get("contributions", {}).values())
    public_good_value = total_contribution * game.multiplier
    
    print(f"ğŸ’° ç·è²¢çŒ®é¡: {total_contribution}")
    print(f"ğŸ å…¬å…±è²¡ä¾¡å€¤: {public_good_value}")
    print(f"ğŸ‘¥ å€‹äººåˆ†é…: {public_good_value / len(agents):.2f}")
    
    print(f"\nğŸ’¼ æœ€çµ‚åˆ©å¾—:")
    for agent_id, payoff in payoffs.items():
        print(f"  {agent_id}: {payoff:.2f}")
    
    print(f"\nğŸ† ç¤¾ä¼šåšç”Ÿ: {sum(payoffs.values()):.2f}")
    
    return state, payoffs, decisions

# å®Ÿè¡Œ
if __name__ == "__main__":
    asyncio.run(run_public_goods_experiment())
```

#### B. ä¿¡é ¼ã‚²ãƒ¼ãƒ å®Ÿé¨“

```python
# trust_game_experiment.py ã¨ã—ã¦ä¿å­˜
import asyncio
from src.multiagent_system.agents.llm_game_agent import LLMGameAgent
from src.multiagent_system.game_theory.advanced_games import TrustGame

async def run_trust_game_experiment():
    print("ğŸ¤ ä¿¡é ¼ã‚²ãƒ¼ãƒ å®Ÿé¨“é–‹å§‹")
    
    # 2äººã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
    trustor = LLMGameAgent("ä¿¡é ¼è€…", {
        "trust_propensity": 0.7,
        "risk_tolerance": 0.6,
        "description": "ä¿¡é ¼ã‚’é‡è¦–ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
    })
    
    trustee = LLMGameAgent("å—è¨—è€…", {
        "integrity": 0.8,
        "benevolence": 0.7,
        "description": "èª å®Ÿæ€§ã‚’é‡è¦–ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
    })
    
    # ã‚²ãƒ¼ãƒ è¨­å®š
    game = TrustGame(
        num_players=2,
        multiplier=3.0,
        endowment=100.0,
        multi_round=False
    )
    
    agents = [trustor, trustee]
    agent_ids = [agent.agent_id for agent in agents]
    state = game.initialize(agent_ids)
    
    print(f"ğŸ’° åˆæœŸè³‡é‡‘: {game.endowment}")
    print(f"ğŸ”¢ ä¿¡é ¼ä¹—æ•°: {game.multiplier}")
    print(f"ğŸ‘¨â€ğŸ’¼ ä¿¡é ¼è€…: {state.public_info['trustor']}")
    print(f"ğŸ‘©â€ğŸ’¼ å—è¨—è€…: {state.public_info['trustee']}")
    
    # ãƒ•ã‚§ãƒ¼ã‚º1: é€é‡‘æ±ºå®š
    print(f"\nğŸ“¤ ãƒ•ã‚§ãƒ¼ã‚º1: é€é‡‘æ±ºå®š")
    trustor_info = game.get_information_set(trustor.agent_id, state)
    send_action, send_reasoning = await trustor.make_decision(game, state, trustor_info)
    
    print(f"ğŸ’¸ é€é‡‘é¡: {send_action.value}")
    print(f"ğŸ§  é€é‡‘ç†ç”±: {send_reasoning.decision_rationale[:100]}...")
    
    state = game.apply_action(send_action, state)
    
    # ãƒ•ã‚§ãƒ¼ã‚º2: è¿”é‡‘æ±ºå®š
    print(f"\nğŸ“¥ ãƒ•ã‚§ãƒ¼ã‚º2: è¿”é‡‘æ±ºå®š")
    multiplied_amount = state.public_info["amount_sent"] * game.multiplier
    print(f"ğŸ å—è¨—è€…å—é ˜é¡: {multiplied_amount}")
    
    trustee_info = game.get_information_set(trustee.agent_id, state)
    return_action, return_reasoning = await trustee.make_decision(game, state, trustee_info)
    
    print(f"ğŸ’° è¿”é‡‘é¡: {return_action.value}")
    print(f"ğŸ§  è¿”é‡‘ç†ç”±: {return_reasoning.decision_rationale[:100]}...")
    
    state = game.apply_action(return_action, state)
    
    # çµæœè¨ˆç®—
    payoffs = game.calculate_payoffs(state)
    
    print(f"\nğŸ“Š å®Ÿé¨“çµæœ:")
    print(f"ğŸ“¤ é€é‡‘é¡: {state.public_info['amount_sent']}")
    print(f"ğŸ“¥ è¿”é‡‘é¡: {state.public_info['amount_returned']}")
    print(f"ğŸ¤ ä¿¡é ¼ç‡: {state.public_info['amount_sent'] / game.endowment:.2%}")
    print(f"ğŸ’« è¿”é‡‘ç‡: {state.public_info['amount_returned'] / multiplied_amount:.2%}")
    
    print(f"\nğŸ’¼ æœ€çµ‚åˆ©å¾—:")
    for agent_id, payoff in payoffs.items():
        role = "ä¿¡é ¼è€…" if agent_id == state.public_info['trustor'] else "å—è¨—è€…"
        print(f"  {role}({agent_id}): {payoff:.2f}")
    
    return state, payoffs

# å®Ÿè¡Œ
if __name__ == "__main__":
    asyncio.run(run_trust_game_experiment())
```

### 3. ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ

```python
# benchmark_runner.py ã¨ã—ã¦ä¿å­˜
import asyncio
from src.experiments.integrated_benchmark_system import IntegratedBenchmarkSystem

async def run_comprehensive_benchmark():
    print("ğŸ¯ åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    benchmark = IntegratedBenchmarkSystem()
    
    # åˆ©ç”¨å¯èƒ½ãªã‚¹ã‚¤ãƒ¼ãƒˆç¢ºèª
    summary = benchmark.get_benchmark_summary()
    print(f"\nğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¤ãƒ¼ãƒˆ:")
    for suite_name, details in summary["suite_details"].items():
        print(f"  ğŸ® {suite_name}: {details['description']}")
        print(f"     ğŸ“Š ã‚¿ã‚¹ã‚¯æ•°: {details['task_count']}")
        print(f"     â±ï¸  äºˆæƒ³æ™‚é–“: {details['estimated_time_minutes']}åˆ†")
        print(f"     ğŸšï¸  è¤‡é›‘åº¦: {details['complexity_range']}")
    
    # åŸºæœ¬ã‚²ãƒ¼ãƒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    print(f"\nğŸš€ åŸºæœ¬ã‚²ãƒ¼ãƒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œä¸­...")
    results = await benchmark.run_benchmark_suite("basic_games")
    
    # çµæœè¡¨ç¤º
    print(f"\nğŸ“Š ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ:")
    success_count = sum(1 for r in results if r.success)
    print(f"  âœ… æˆåŠŸ: {success_count}/{len(results)} ã‚¿ã‚¹ã‚¯")
    print(f"  ğŸ“ˆ å¹³å‡ã‚¹ã‚³ã‚¢: {sum(r.score for r in results) / len(results):.1f}")
    
    print(f"\nğŸ“‹ è©³ç´°çµæœ:")
    for result in results:
        status = "âœ…" if result.success else "âŒ"
        print(f"  {status} {result.task_id}: {result.score:.1f}ç‚¹")
        if result.failure_reasons:
            for reason in result.failure_reasons:
                print(f"      âš ï¸  {reason}")
    
    return results

# å®Ÿè¡Œ
if __name__ == "__main__":
    asyncio.run(run_comprehensive_benchmark())
```

## é«˜åº¦ãªå®Ÿé¨“æ‰‹é †

### 1. ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ€§æ ¼ã®ä½œæˆ

```python
# custom_personalities.py ã¨ã—ã¦ä¿å­˜
from src.multiagent_system.agents.llm_game_agent import LLMGameAgent

# é«˜åº¦ãªæ€§æ ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å®šç¾©
ADVANCED_PERSONALITIES = {
    "æ…é‡ãªå”åŠ›è€…": {
        "cooperation_tendency": 0.85,
        "risk_tolerance": 0.25,
        "trust_propensity": 0.75,
        "rationality": 0.90,
        "learning_speed": 0.30,
        "communication_style": "cautious",
        "description": "ãƒªã‚¹ã‚¯ã‚’é¿ã‘ã¤ã¤é•·æœŸçš„å”åŠ›ã‚’é‡è¦–ã™ã‚‹æ…é‡ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
    },
    "ç©æ¥µçš„ç«¶äº‰è€…": {
        "cooperation_tendency": 0.20,
        "risk_tolerance": 0.90,
        "trust_propensity": 0.30,
        "rationality": 0.80,
        "learning_speed": 0.70,
        "communication_style": "aggressive",
        "description": "é«˜ãƒªã‚¹ã‚¯é«˜ãƒªã‚¿ãƒ¼ãƒ³ã‚’ç‹™ã†ç©æ¥µçš„ãªç«¶äº‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
    },
    "ãƒãƒ©ãƒ³ã‚¹å‹å­¦ç¿’è€…": {
        "cooperation_tendency": 0.50,
        "risk_tolerance": 0.50,
        "trust_propensity": 0.50,
        "rationality": 0.95,
        "learning_speed": 0.80,
        "communication_style": "adaptive",
        "description": "çŠ¶æ³åˆ†æã¨é©å¿œå­¦ç¿’ã«å„ªã‚ŒãŸãƒãƒ©ãƒ³ã‚¹å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
    },
    "ä¿¡é ¼æ§‹ç¯‰è€…": {
        "cooperation_tendency": 0.75,
        "risk_tolerance": 0.40,
        "trust_propensity": 0.85,
        "rationality": 0.85,
        "learning_speed": 0.50,
        "communication_style": "diplomatic",
        "description": "ä¿¡é ¼é–¢ä¿‚ã®æ§‹ç¯‰ã‚’æœ€å„ªå…ˆã¨ã™ã‚‹å¤–äº¤çš„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
    },
    "æ©Ÿä¼šä¸»ç¾©è€…": {
        "cooperation_tendency": 0.40,
        "risk_tolerance": 0.70,
        "trust_propensity": 0.45,
        "rationality": 0.90,
        "learning_speed": 0.60,
        "communication_style": "opportunistic",
        "description": "çŠ¶æ³ã«å¿œã˜ã¦æœ€é©ãªé¸æŠã‚’è¿½æ±‚ã™ã‚‹æ©Ÿä¼šä¸»ç¾©çš„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
    }
}

def create_diverse_agent_pool(personalities=None):
    """å¤šæ§˜ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ—ãƒ¼ãƒ«ã‚’ä½œæˆ"""
    if personalities is None:
        personalities = ADVANCED_PERSONALITIES
    
    agents = []
    for name, personality in personalities.items():
        agent = LLMGameAgent(name, personality)
        agents.append(agent)
        print(f"âœ… {name}: {personality['description']}")
    
    return agents

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    agents = create_diverse_agent_pool()
    print(f"\nğŸ¯ {len(agents)}ä½“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆå®Œäº†")
```

### 2. ãƒãƒ«ãƒã‚²ãƒ¼ãƒ å®Ÿé¨“ã‚·ãƒªãƒ¼ã‚º

```python
# multi_game_experiment.py ã¨ã—ã¦ä¿å­˜
import asyncio
from src.experiments.advanced_game_experiments import ExperimentConfig, AdvancedGameExperimentSuite
from src.multiagent_system.game_theory.advanced_games import GameType
from custom_personalities import ADVANCED_PERSONALITIES

async def run_multi_game_experiment_series():
    print("ğŸ¯ ãƒãƒ«ãƒã‚²ãƒ¼ãƒ å®Ÿé¨“ã‚·ãƒªãƒ¼ã‚ºé–‹å§‹")
    
    # å®Ÿé¨“è¨­å®š
    config = ExperimentConfig(
        name="multi_game_personality_study",
        num_agents=5,
        num_rounds=15,
        num_trials=3,
        games_to_test=[
            GameType.PUBLIC_GOODS,
            GameType.TRUST_GAME,
            GameType.AUCTION,
            GameType.NETWORK_FORMATION
        ],
        agent_personalities=list(ADVANCED_PERSONALITIES.values()),
        output_dir="results/multi_game_study",
        save_detailed_logs=True,
        visualize_results=True
    )
    
    print(f"ğŸ® å¯¾è±¡ã‚²ãƒ¼ãƒ : {[g.value for g in config.games_to_test]}")
    print(f"ğŸ‘¥ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ•°: {config.num_agents}")
    print(f"ğŸ”„ ãƒ©ã‚¦ãƒ³ãƒ‰æ•°: {config.num_rounds}")
    print(f"ğŸ² è©¦è¡Œå›æ•°: {config.num_trials}")
    
    # å®Ÿé¨“å®Ÿè¡Œ
    suite = AdvancedGameExperimentSuite(config)
    results = suite.run_comprehensive_experiment()
    
    print(f"\nğŸ“Š å®Ÿé¨“å®Œäº†:")
    print(f"  ğŸ“‹ ç·å®Ÿé¨“æ•°: {len(results)}")
    print(f"  â±ï¸  å®Ÿè¡Œæ™‚é–“: {sum(r.execution_time for r in results):.1f}ç§’")
    print(f"  ğŸ’¾ çµæœä¿å­˜å…ˆ: {config.output_dir}")
    
    # çµæœè¦ç´„
    game_performance = {}
    for result in results:
        game_type = result.experiment_id.split('_')[0]
        if game_type not in game_performance:
            game_performance[game_type] = []
        game_performance[game_type].append({
            'cooperation': result.performance_metrics.get('avg_cooperation', 0),
            'social_welfare': result.performance_metrics.get('avg_social_welfare', 0),
            'fairness': result.performance_metrics.get('avg_fairness', 0)
        })
    
    print(f"\nğŸ“ˆ ã‚²ãƒ¼ãƒ åˆ¥æ€§èƒ½è¦ç´„:")
    for game_type, performances in game_performance.items():
        avg_coop = sum(p['cooperation'] for p in performances) / len(performances)
        avg_welfare = sum(p['social_welfare'] for p in performances) / len(performances)
        avg_fairness = sum(p['fairness'] for p in performances) / len(performances)
        
        print(f"  ğŸ® {game_type}:")
        print(f"    ğŸ¤ å¹³å‡å”åŠ›ãƒ¬ãƒ™ãƒ«: {avg_coop:.3f}")
        print(f"    ğŸ’° å¹³å‡ç¤¾ä¼šåšç”Ÿ: {avg_welfare:.2f}")
        print(f"    âš–ï¸  å¹³å‡å…¬å¹³æ€§: {avg_fairness:.3f}")
    
    return results

# å®Ÿè¡Œ
if __name__ == "__main__":
    asyncio.run(run_multi_game_experiment_series())
```

### 3. çŸ¥è­˜äº¤æ›ãƒ»ä¿¡é ¼ã‚·ã‚¹ãƒ†ãƒ çµ±åˆå®Ÿé¨“

```python
# knowledge_trust_integration.py ã¨ã—ã¦ä¿å­˜
import asyncio
from src.multiagent_system.knowledge.knowledge_exchange_system import (
    KnowledgeMarket, CollaborativeKnowledgeSystem, KnowledgeItem, KnowledgeType
)
from src.multiagent_system.reputation.trust_reputation_system import (
    TrustReputationSystem, InteractionType
)
from custom_personalities import create_diverse_agent_pool

async def run_knowledge_trust_integration():
    print("ğŸ§  çŸ¥è­˜äº¤æ›ãƒ»ä¿¡é ¼ã‚·ã‚¹ãƒ†ãƒ çµ±åˆå®Ÿé¨“")
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    knowledge_system = CollaborativeKnowledgeSystem()
    trust_system = TrustReputationSystem()
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
    agents = create_diverse_agent_pool()
    agent_ids = [agent.agent_id for agent in agents]
    
    # ä¿¡é ¼ã‚·ã‚¹ãƒ†ãƒ ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç™»éŒ²
    for agent_id in agent_ids:
        trust_system.register_agent(agent_id)
    
    print(f"\nğŸ‘¥ {len(agents)}ä½“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç™»éŒ²å®Œäº†")
    
    # å”èª¿ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
    session_id = "collaborative_problem_solving_001"
    problem = "ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹æœ€é©ãªå”åŠ›æˆ¦ç•¥ã®è¨­è¨ˆ"
    
    success = await knowledge_system.create_collaborative_session(
        session_id=session_id,
        participants=agent_ids,
        problem_description=problem,
        session_type="strategic_design"
    )
    
    if not success:
        print("âŒ å”èª¿ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆå¤±æ•—")
        return
    
    print(f"âœ… å”èª¿ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ: {session_id}")
    print(f"ğŸ¯ å•é¡Œ: {problem}")
    
    # çŸ¥è­˜å…±æœ‰ãƒ•ã‚§ãƒ¼ã‚º
    print(f"\nğŸ“š ãƒ•ã‚§ãƒ¼ã‚º1: çŸ¥è­˜å…±æœ‰")
    knowledge_contributions = [
        ("æ…é‡ãªå”åŠ›è€…", "é•·æœŸçš„é–¢ä¿‚ã§ã¯ä¿¡é ¼æ§‹ç¯‰ãŒé‡è¦", ["trust_building", "long_term_strategy"]),
        ("ç©æ¥µçš„ç«¶äº‰è€…", "çŸ­æœŸçš„ã«ã¯ç«¶äº‰ãŒåŠ¹ç‡çš„", ["competition", "efficiency"]),
        ("ãƒãƒ©ãƒ³ã‚¹å‹å­¦ç¿’è€…", "çŠ¶æ³ã«å¿œã˜ãŸé©å¿œæˆ¦ç•¥ãŒæœ€é©", ["adaptation", "situational_analysis"]),
        ("ä¿¡é ¼æ§‹ç¯‰è€…", "é€æ˜æ€§ã¨ä¸€è²«æ€§ãŒä¿¡é ¼ã®åŸºç›¤", ["transparency", "consistency"]),
        ("æ©Ÿä¼šä¸»ç¾©è€…", "ã‚¤ãƒ³ã‚»ãƒ³ãƒ†ã‚£ãƒ–è¨­è¨ˆãŒè¡Œå‹•å¤‰åŒ–ã®éµ", ["incentives", "mechanism_design"])
    ]
    
    for contributor, knowledge, references in knowledge_contributions:
        await knowledge_system.contribute_to_session(
            session_id=session_id,
            contributor=contributor,
            contribution_type="knowledge_share",
            content=knowledge,
            knowledge_references=references
        )
        print(f"  ğŸ“ {contributor}: {knowledge[:50]}...")
        
        # ä¿¡é ¼ã‚·ã‚¹ãƒ†ãƒ ã«è¨˜éŒ²
        for other_agent in agent_ids:
            if other_agent != contributor:
                trust_system.record_interaction(
                    agent_a=contributor,
                    agent_b=other_agent,
                    interaction_type=InteractionType.KNOWLEDGE_EXCHANGE,
                    outcome="success",
                    details={"knowledge_shared": True},
                    satisfaction_a=0.8,
                    satisfaction_b=0.7,
                    context="collaborative_session"
                )
    
    # æ´å¯Ÿç”Ÿæˆãƒ•ã‚§ãƒ¼ã‚º
    print(f"\nğŸ’¡ ãƒ•ã‚§ãƒ¼ã‚º2: æ´å¯Ÿç”Ÿæˆ")
    insights = [
        ("ãƒãƒ©ãƒ³ã‚¹å‹å­¦ç¿’è€…", "ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®çµ±åˆã«ã‚ˆã‚Šç›¸ä¹—åŠ¹æœãŒæœŸå¾…ã§ãã‚‹"),
        ("ä¿¡é ¼æ§‹ç¯‰è€…", "ä¿¡é ¼ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¨ç«¶äº‰åŸç†ã®é©åˆ‡ãªãƒãƒ©ãƒ³ã‚¹ãŒé‡è¦"),
        ("æ©Ÿä¼šä¸»ç¾©è€…", "å‹•çš„ã‚¤ãƒ³ã‚»ãƒ³ãƒ†ã‚£ãƒ–è¨­è¨ˆã«ã‚ˆã‚Šé©å¿œçš„å”åŠ›ã‚’å®Ÿç¾å¯èƒ½")
    ]
    
    for contributor, insight in insights:
        await knowledge_system.contribute_to_session(
            session_id=session_id,
            contributor=contributor,
            contribution_type="insight",
            content=insight
        )
        print(f"  ğŸ”¬ {contributor}: {insight[:50]}...")
    
    # ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ææ¡ˆãƒ•ã‚§ãƒ¼ã‚º
    print(f"\nğŸ¯ ãƒ•ã‚§ãƒ¼ã‚º3: ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ææ¡ˆ")
    solutions = [
        ("æ…é‡ãªå”åŠ›è€…", "æ®µéšçš„ä¿¡é ¼æ§‹ç¯‰ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®å®Ÿè£…"),
        ("ç©æ¥µçš„ç«¶äº‰è€…", "å‹•çš„ç«¶äº‰ãƒ»å”åŠ›åˆ‡ã‚Šæ›¿ãˆã‚·ã‚¹ãƒ†ãƒ "),
        ("ä¿¡é ¼æ§‹ç¯‰è€…", "é€æ˜æ€§ä¿è¨¼ä»˜ããƒãƒ«ãƒãƒ¬ãƒ™ãƒ«å”åŠ›ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯")
    ]
    
    for proposer, solution in solutions:
        await knowledge_system.contribute_to_session(
            session_id=session_id,
            contributor=proposer,
            contribution_type="solution_proposal",
            content=solution
        )
        print(f"  ğŸ† {proposer}: {solution}")
    
    # æŠ•ç¥¨ãƒ•ã‚§ãƒ¼ã‚º
    print(f"\nğŸ—³ï¸  ãƒ•ã‚§ãƒ¼ã‚º4: ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡")
    for i, (proposer, solution) in enumerate(solutions):
        votes = 0
        for voter in agent_ids:
            if voter != proposer:
                # ä¿¡é ¼ãƒ¬ãƒ™ãƒ«ã«åŸºã¥ãæŠ•ç¥¨
                trust_score = trust_system.get_trust_score(voter, proposer)
                vote = "approve" if trust_score and trust_score.overall > 0.6 else "neutral"
                
                await knowledge_system.vote_on_solution(
                    session_id=session_id,
                    solution_index=i,
                    voter=voter,
                    vote=vote,
                    rationale=f"ä¿¡é ¼åº¦{trust_score.overall:.2f}ã«åŸºã¥ãæŠ•ç¥¨"
                )
                
                if vote == "approve":
                    votes += 1
        
        print(f"  ğŸ“Š {solution}: {votes}/{len(agent_ids)-1}ç¥¨")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„
    summary = knowledge_system.get_session_summary(session_id)
    print(f"\nğŸ“‹ ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„:")
    print(f"  â±ï¸  ç¶™ç¶šæ™‚é–“: {summary['duration_minutes']:.1f}åˆ†")
    print(f"  ğŸ’¬ ç·è²¢çŒ®æ•°: {summary['total_contributions']}")
    print(f"  ğŸ“š çŸ¥è­˜å…±æœ‰: {summary['knowledge_shared']}")
    print(f"  ğŸ’¡ æ´å¯Ÿç”Ÿæˆ: {summary['insights_generated']}")
    print(f"  ğŸ¯ ææ¡ˆæ•°: {summary['solutions_proposed']}")
    print(f"  ğŸ‘‘ æœ€æ´»ç™º: {summary['most_active_participant']}")
    
    # ä¿¡é ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ
    network_metrics = trust_system.get_trust_network_metrics()
    print(f"\nğŸ•¸ï¸  ä¿¡é ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ:")
    print(f"  ğŸ‘¥ ãƒãƒ¼ãƒ‰æ•°: {network_metrics['num_agents']}")
    print(f"  ğŸ”— ä¿¡é ¼é–¢ä¿‚æ•°: {network_metrics['num_trust_relationships']}")
    print(f"  ğŸ“Š ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯†åº¦: {network_metrics['network_density']:.3f}")
    print(f"  ğŸ¤ å¹³å‡ä¿¡é ¼åº¦: {network_metrics.get('average_trust', 0):.3f}")
    print(f"  â­ ä¸­å¿ƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: {network_metrics.get('most_central_agent', 'N/A')}")
    
    # é›†åˆçŸ¥è­˜æŠ½å‡º
    collective_knowledge = knowledge_system.extract_collective_knowledge(session_id)
    print(f"\nğŸ§  æŠ½å‡ºã•ã‚ŒãŸé›†åˆçŸ¥è­˜: {len(collective_knowledge)}é …ç›®")
    for knowledge in collective_knowledge:
        print(f"  ğŸ“– {knowledge.content[:60]}... (ä¿¡é ¼åº¦: {knowledge.confidence:.2f})")
    
    return summary, network_metrics, collective_knowledge

# å®Ÿè¡Œ
if __name__ == "__main__":
    asyncio.run(run_knowledge_trust_integration())
```

## çµæœåˆ†ææ–¹æ³•

### 1. å®Ÿé¨“çµæœã®èª­ã¿è¾¼ã¿ã¨åŸºæœ¬åˆ†æ

```python
# result_analysis.py ã¨ã—ã¦ä¿å­˜
import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from pathlib import Path

def load_experiment_results(results_dir="results"):
    """å®Ÿé¨“çµæœã‚’èª­ã¿è¾¼ã¿"""
    results_path = Path(results_dir)
    all_results = {}
    
    # å„å®Ÿé¨“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª
    for experiment_dir in results_path.iterdir():
        if experiment_dir.is_dir():
            experiment_name = experiment_dir.name
            all_results[experiment_name] = {}
            
            # JSONçµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            for result_file in experiment_dir.glob("*.json"):
                try:
                    with open(result_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    all_results[experiment_name][result_file.stem] = data
                    print(f"âœ… èª­ã¿è¾¼ã¿: {experiment_name}/{result_file.name}")
                except Exception as e:
                    print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result_file}: {e}")
    
    return all_results

def analyze_cooperation_trends(results_data):
    """å”åŠ›ãƒ¬ãƒ™ãƒ«ã®å‚¾å‘åˆ†æ"""
    cooperation_data = []
    
    for experiment_name, experiments in results_data.items():
        for exp_id, exp_data in experiments.items():
            if 'outcomes' in exp_data:
                for i, outcome in enumerate(exp_data['outcomes']):
                    cooperation_data.append({
                        'experiment': experiment_name,
                        'trial': exp_id,
                        'round': i,
                        'cooperation_level': outcome.get('cooperation_level', 0),
                        'social_welfare': outcome.get('social_welfare', 0),
                        'fairness_index': outcome.get('fairness_index', 0)
                    })
    
    df = pd.DataFrame(cooperation_data)
    
    if df.empty:
        print("âš ï¸  å”åŠ›ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return df
    
    # åŸºæœ¬çµ±è¨ˆ
    print(f"ğŸ“Š å”åŠ›ãƒ¬ãƒ™ãƒ«çµ±è¨ˆ:")
    print(f"  å¹³å‡: {df['cooperation_level'].mean():.3f}")
    print(f"  æ¨™æº–åå·®: {df['cooperation_level'].std():.3f}")
    print(f"  æœ€å°å€¤: {df['cooperation_level'].min():.3f}")
    print(f"  æœ€å¤§å€¤: {df['cooperation_level'].max():.3f}")
    
    # å®Ÿé¨“åˆ¥çµ±è¨ˆ
    exp_stats = df.groupby('experiment')['cooperation_level'].agg(['mean', 'std', 'count'])
    print(f"\nğŸ“‹ å®Ÿé¨“åˆ¥å”åŠ›ãƒ¬ãƒ™ãƒ«:")
    for exp_name, stats in exp_stats.iterrows():
        print(f"  {exp_name}: {stats['mean']:.3f} Â± {stats['std']:.3f} (n={stats['count']})")
    
    return df

def create_comprehensive_visualization(cooperation_df):
    """åŒ…æ‹¬çš„ãªå¯è¦–åŒ–"""
    if cooperation_df.empty:
        print("âš ï¸  å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # å›³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    plt.style.use('seaborn-v0_8')
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿé¨“çµæœåˆ†æ', fontsize=16, fontweight='bold')
    
    # 1. å”åŠ›ãƒ¬ãƒ™ãƒ«ã®æ™‚ç³»åˆ—å¤‰åŒ–
    for experiment in cooperation_df['experiment'].unique():
        exp_data = cooperation_df[cooperation_df['experiment'] == experiment]
        exp_avg = exp_data.groupby('round')['cooperation_level'].mean()
        axes[0, 0].plot(exp_avg.index, exp_avg.values, label=experiment, marker='o')
    
    axes[0, 0].set_title('å”åŠ›ãƒ¬ãƒ™ãƒ«ã®æ™‚ç³»åˆ—å¤‰åŒ–')
    axes[0, 0].set_xlabel('ãƒ©ã‚¦ãƒ³ãƒ‰')
    axes[0, 0].set_ylabel('å”åŠ›ãƒ¬ãƒ™ãƒ«')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. å®Ÿé¨“åˆ¥å”åŠ›ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ
    sns.boxplot(data=cooperation_df, x='experiment', y='cooperation_level', ax=axes[0, 1])
    axes[0, 1].set_title('å®Ÿé¨“åˆ¥å”åŠ›ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ')
    axes[0, 1].set_xlabel('å®Ÿé¨“')
    axes[0, 1].set_ylabel('å”åŠ›ãƒ¬ãƒ™ãƒ«')
    axes[0, 1].tick_params(axis='x', rotation=45)
    
    # 3. ç¤¾ä¼šåšç”Ÿvså”åŠ›ãƒ¬ãƒ™ãƒ«
    axes[0, 2].scatter(cooperation_df['cooperation_level'], cooperation_df['social_welfare'], 
                      alpha=0.6, c=cooperation_df['fairness_index'], cmap='viridis')
    axes[0, 2].set_title('å”åŠ›ãƒ¬ãƒ™ãƒ« vs ç¤¾ä¼šåšç”Ÿ')
    axes[0, 2].set_xlabel('å”åŠ›ãƒ¬ãƒ™ãƒ«')
    axes[0, 2].set_ylabel('ç¤¾ä¼šåšç”Ÿ')
    cbar = plt.colorbar(axes[0, 2].collections[0], ax=axes[0, 2])
    cbar.set_label('å…¬å¹³æ€§æŒ‡æ•°')
    
    # 4. å…¬å¹³æ€§æŒ‡æ•°ã®åˆ†å¸ƒ
    axes[1, 0].hist(cooperation_df['fairness_index'], bins=30, alpha=0.7, edgecolor='black')
    axes[1, 0].set_title('å…¬å¹³æ€§æŒ‡æ•°ã®åˆ†å¸ƒ')
    axes[1, 0].set_xlabel('å…¬å¹³æ€§æŒ‡æ•°')
    axes[1, 0].set_ylabel('é »åº¦')
    axes[1, 0].axvline(cooperation_df['fairness_index'].mean(), color='red', 
                      linestyle='--', label=f'å¹³å‡: {cooperation_df["fairness_index"].mean():.3f}')
    axes[1, 0].legend()
    
    # 5. ç›¸é–¢é–¢ä¿‚ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    corr_data = cooperation_df[['cooperation_level', 'social_welfare', 'fairness_index']].corr()
    sns.heatmap(corr_data, annot=True, cmap='coolwarm', center=0, ax=axes[1, 1])
    axes[1, 1].set_title('æŒ‡æ¨™é–“ç›¸é–¢é–¢ä¿‚')
    
    # 6. å®Ÿé¨“åˆ¥æˆåŠŸç‡ï¼ˆå”åŠ›ãƒ¬ãƒ™ãƒ«>0.5ï¼‰
    cooperation_df['high_cooperation'] = cooperation_df['cooperation_level'] > 0.5
    success_rates = cooperation_df.groupby('experiment')['high_cooperation'].mean()
    axes[1, 2].bar(range(len(success_rates)), success_rates.values)
    axes[1, 2].set_title('é«˜å”åŠ›ç‡ï¼ˆ>0.5ï¼‰ã®é”æˆç‡')
    axes[1, 2].set_xlabel('å®Ÿé¨“')
    axes[1, 2].set_ylabel('é”æˆç‡')
    axes[1, 2].set_xticks(range(len(success_rates)))
    axes[1, 2].set_xticklabels(success_rates.index, rotation=45)
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
    plt.tight_layout()
    
    # ä¿å­˜
    output_path = Path("results/comprehensive_analysis.png")
    output_path.parent.mkdir(exist_ok=True)
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š å¯è¦–åŒ–ä¿å­˜: {output_path}")
    
    plt.show()

def generate_analysis_report(results_data, cooperation_df):
    """åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    report_lines = [
        "# ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿé¨“åˆ†æãƒ¬ãƒãƒ¼ãƒˆ",
        f"**ç”Ÿæˆæ—¥æ™‚**: {pd.Timestamp.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}",
        "",
        "## å®Ÿé¨“æ¦‚è¦",
        f"- **å®Ÿé¨“æ•°**: {len(results_data)}",
        f"- **ç·ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ**: {len(cooperation_df)}",
        ""
    ]
    
    if not cooperation_df.empty:
        # åŸºæœ¬çµ±è¨ˆ
        report_lines.extend([
            "## å”åŠ›ãƒ¬ãƒ™ãƒ«çµ±è¨ˆ",
            f"- **å¹³å‡å”åŠ›ãƒ¬ãƒ™ãƒ«**: {cooperation_df['cooperation_level'].mean():.3f}",
            f"- **æ¨™æº–åå·®**: {cooperation_df['cooperation_level'].std():.3f}",
            f"- **æœ€å°å€¤**: {cooperation_df['cooperation_level'].min():.3f}",
            f"- **æœ€å¤§å€¤**: {cooperation_df['cooperation_level'].max():.3f}",
            "",
            "## ç¤¾ä¼šåšç”Ÿçµ±è¨ˆ", 
            f"- **å¹³å‡ç¤¾ä¼šåšç”Ÿ**: {cooperation_df['social_welfare'].mean():.2f}",
            f"- **æ¨™æº–åå·®**: {cooperation_df['social_welfare'].std():.2f}",
            "",
            "## å…¬å¹³æ€§çµ±è¨ˆ",
            f"- **å¹³å‡å…¬å¹³æ€§æŒ‡æ•°**: {cooperation_df['fairness_index'].mean():.3f}",
            f"- **æ¨™æº–åå·®**: {cooperation_df['fairness_index'].std():.3f}",
            ""
        ])
        
        # å®Ÿé¨“åˆ¥æ¯”è¼ƒ
        if 'experiment' in cooperation_df.columns:
            exp_stats = cooperation_df.groupby('experiment').agg({
                'cooperation_level': ['mean', 'std'],
                'social_welfare': ['mean', 'std'],
                'fairness_index': ['mean', 'std']
            }).round(3)
            
            report_lines.append("## å®Ÿé¨“åˆ¥æ¯”è¼ƒ")
            for exp_name in exp_stats.index:
                stats = exp_stats.loc[exp_name]
                report_lines.extend([
                    f"### {exp_name}",
                    f"- **å”åŠ›ãƒ¬ãƒ™ãƒ«**: {stats[('cooperation_level', 'mean')]:.3f} Â± {stats[('cooperation_level', 'std')]:.3f}",
                    f"- **ç¤¾ä¼šåšç”Ÿ**: {stats[('social_welfare', 'mean')]:.2f} Â± {stats[('social_welfare', 'std')]:.2f}",
                    f"- **å…¬å¹³æ€§æŒ‡æ•°**: {stats[('fairness_index', 'mean')]:.3f} Â± {stats[('fairness_index', 'std')]:.3f}",
                    ""
                ])
        
        # ç›¸é–¢åˆ†æ
        corr_matrix = cooperation_df[['cooperation_level', 'social_welfare', 'fairness_index']].corr()
        report_lines.extend([
            "## æŒ‡æ¨™é–“ç›¸é–¢åˆ†æ",
            f"- **å”åŠ›ãƒ¬ãƒ™ãƒ« vs ç¤¾ä¼šåšç”Ÿ**: {corr_matrix.loc['cooperation_level', 'social_welfare']:.3f}",
            f"- **å”åŠ›ãƒ¬ãƒ™ãƒ« vs å…¬å¹³æ€§**: {corr_matrix.loc['cooperation_level', 'fairness_index']:.3f}",
            f"- **ç¤¾ä¼šåšç”Ÿ vs å…¬å¹³æ€§**: {corr_matrix.loc['social_welfare', 'fairness_index']:.3f}",
            ""
        ])
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    report_path = Path("results/analysis_report.md")
    report_path.parent.mkdir(exist_ok=True)
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_lines))
    
    print(f"ğŸ“„ åˆ†æãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
    return report_path

# ãƒ¡ã‚¤ãƒ³åˆ†æé–¢æ•°
def run_comprehensive_analysis():
    """åŒ…æ‹¬çš„åˆ†æå®Ÿè¡Œ"""
    print("ğŸ“Š åŒ…æ‹¬çš„çµæœåˆ†æé–‹å§‹")
    
    # çµæœèª­ã¿è¾¼ã¿
    results_data = load_experiment_results()
    
    if not results_data:
        print("âš ï¸  åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # å”åŠ›ãƒ‡ãƒ¼ã‚¿åˆ†æ
    cooperation_df = analyze_cooperation_trends(results_data)
    
    # å¯è¦–åŒ–ä½œæˆ
    create_comprehensive_visualization(cooperation_df)
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report_path = generate_analysis_report(results_data, cooperation_df)
    
    print(f"\nâœ… åˆ†æå®Œäº†")
    print(f"ğŸ“Š å¯è¦–åŒ–: results/comprehensive_analysis.png")
    print(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")
    
    return results_data, cooperation_df

if __name__ == "__main__":
    run_comprehensive_analysis()
```

## ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ–¹æ³•

### 1. æ–°ã—ã„ã‚²ãƒ¼ãƒ ã‚¿ã‚¤ãƒ—ã®å®Ÿè£…

```python
# custom_coordination_game.py ã¨ã—ã¦ä¿å­˜
from typing import Dict, List
from src.multiagent_system.game_theory.advanced_games import (
    AdvancedGame, GameType, Action, GameState, GameOutcome
)

class CoordinationGame(AdvancedGame):
    """
    å”èª¿ã‚²ãƒ¼ãƒ å®Ÿè£…ä¾‹
    
    è¤‡æ•°ã®å‡è¡¡ç‚¹ã‚’æŒã¤å”èª¿å•é¡Œã‚’ãƒ¢ãƒ‡ãƒ«åŒ–
    """
    
    def __init__(self, num_players: int, **kwargs):
        super().__init__(GameType.COORDINATION, num_players, **kwargs)
        self.coordination_threshold = kwargs.get("coordination_threshold", 0.7)
        self.coordination_bonus = kwargs.get("coordination_bonus", 50.0)
        self.base_payoff = kwargs.get("base_payoff", 10.0)
    
    def initialize(self, players: List[str]) -> GameState:
        return GameState(
            players=players,
            public_info={
                "coordination_target": "strategy_A",  # ã¾ãŸã¯ "strategy_B"
                "choices": {},
                "coordination_achieved": False
            },
            private_info={
                p: {"preferred_strategy": None, "choice_made": False} 
                for p in players
            }
        )
    
    def is_valid_action(self, action: Action, state: GameState) -> bool:
        if action.agent_id not in state.players:
            return False
        
        if state.private_info[action.agent_id]["choice_made"]:
            return False  # æ—¢ã«é¸æŠæ¸ˆã¿
        
        return action.action_type in ["strategy_A", "strategy_B"]
    
    def apply_action(self, action: Action, state: GameState) -> GameState:
        new_state = state.model_copy(deep=True)
        
        # é¸æŠã‚’è¨˜éŒ²
        new_state.public_info["choices"][action.agent_id] = action.action_type
        new_state.private_info[action.agent_id]["choice_made"] = True
        
        # å…¨å“¡ãŒé¸æŠã—ãŸã‹ãƒã‚§ãƒƒã‚¯
        if len(new_state.public_info["choices"]) == len(new_state.players):
            # å”èª¿é”æˆåˆ¤å®š
            choices = list(new_state.public_info["choices"].values())
            strategy_a_count = choices.count("strategy_A")
            strategy_b_count = choices.count("strategy_B")
            
            # é–¾å€¤ä»¥ä¸ŠãŒåŒã˜æˆ¦ç•¥ã‚’é¸æŠã—ãŸå ´åˆã€å”èª¿é”æˆ
            total_players = len(new_state.players)
            coordination_rate = max(strategy_a_count, strategy_b_count) / total_players
            
            new_state.public_info["coordination_achieved"] = coordination_rate >= self.coordination_threshold
            new_state.terminated = True
        
        return new_state
    
    def calculate_payoffs(self, state: GameState) -> Dict[str, float]:
        payoffs = {}
        choices = state.public_info["choices"]
        coordination_achieved = state.public_info["coordination_achieved"]
        
        for player in state.players:
            # åŸºæœ¬å ±é…¬
            payoff = self.base_payoff
            
            # å”èª¿é”æˆãƒœãƒ¼ãƒŠã‚¹
            if coordination_achieved:
                payoff += self.coordination_bonus
            
            # å€‹åˆ¥æˆ¦ç•¥ãƒœãƒ¼ãƒŠã‚¹ï¼ˆæˆ¦ç•¥AãŒã‚ãšã‹ã«æœ‰åˆ©ï¼‰
            if choices.get(player) == "strategy_A":
                payoff += 2.0
            
            payoffs[player] = payoff
        
        return payoffs
    
    def is_terminal(self, state: GameState) -> bool:
        return state.terminated

# ä½¿ç”¨ä¾‹
async def test_coordination_game():
    from src.multiagent_system.agents.llm_game_agent import LLMGameAgent
    
    print("ğŸ¯ å”èª¿ã‚²ãƒ¼ãƒ ãƒ†ã‚¹ãƒˆ")
    
    # ã‚²ãƒ¼ãƒ ä½œæˆ
    game = CoordinationGame(
        num_players=4,
        coordination_threshold=0.75,
        coordination_bonus=100.0,
        base_payoff=20.0
    )
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
    agents = [
        LLMGameAgent("å”èª¿è€…A", {"cooperation_tendency": 0.9}),
        LLMGameAgent("å”èª¿è€…B", {"cooperation_tendency": 0.8}),
        LLMGameAgent("ç‹¬ç«‹è€…", {"cooperation_tendency": 0.3}),
        LLMGameAgent("è¦³å¯Ÿè€…", {"cooperation_tendency": 0.6})
    ]
    
    # ã‚²ãƒ¼ãƒ å®Ÿè¡Œ
    agent_ids = [agent.agent_id for agent in agents]
    state = game.initialize(agent_ids)
    
    print(f"ğŸ® å”èª¿ã‚²ãƒ¼ãƒ é–‹å§‹")
    print(f"ğŸ“Š å”èª¿é–¾å€¤: {game.coordination_threshold}")
    print(f"ğŸ å”èª¿ãƒœãƒ¼ãƒŠã‚¹: {game.coordination_bonus}")
    
    # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é¸æŠ
    for agent in agents:
        info_set = game.get_information_set(agent.agent_id, state)
        action, reasoning = await agent.make_decision(game, state, info_set)
        
        print(f"ğŸ¤” {agent.agent_id}: {action.action_type}")
        print(f"   ç†ç”±: {reasoning.decision_rationale[:50]}...")
        
        state = game.apply_action(action, state)
    
    # çµæœ
    payoffs = game.calculate_payoffs(state)
    coordination_achieved = state.public_info["coordination_achieved"]
    
    print(f"\nğŸ“Š çµæœ:")
    print(f"ğŸ¤ å”èª¿é”æˆ: {'âœ…' if coordination_achieved else 'âŒ'}")
    
    choices = state.public_info["choices"]
    strategy_counts = {"strategy_A": 0, "strategy_B": 0}
    for choice in choices.values():
        strategy_counts[choice] += 1
    
    print(f"ğŸ“ˆ æˆ¦ç•¥åˆ†å¸ƒ:")
    print(f"  æˆ¦ç•¥A: {strategy_counts['strategy_A']}äºº")
    print(f"  æˆ¦ç•¥B: {strategy_counts['strategy_B']}äºº")
    
    print(f"\nğŸ’° æœ€çµ‚å ±é…¬:")
    for agent_id, payoff in payoffs.items():
        print(f"  {agent_id}: {payoff:.1f}")
    
    return state, payoffs

if __name__ == "__main__":
    import asyncio
    asyncio.run(test_coordination_game())
```

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 1. ä¸€èˆ¬çš„ãªå•é¡Œã¨è§£æ±ºæ–¹æ³•

```bash
# ç’°å¢ƒå•é¡Œã®ãƒã‚§ãƒƒã‚¯ã¨ä¿®å¾©
check_and_fix_environment() {
    echo "ğŸ” ç’°å¢ƒè¨ºæ–­é–‹å§‹..."
    
    # Pythonç’°å¢ƒç¢ºèª
    if ! command -v python &> /dev/null; then
        echo "âŒ PythonãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        echo "è§£æ±ºæ–¹æ³•: Python 3.12+ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„"
        return 1
    fi
    
    python_version=$(python --version 2>&1 | cut -d' ' -f2)
    echo "âœ… Python: $python_version"
    
    # ä»®æƒ³ç’°å¢ƒç¢ºèª
    if [[ "$VIRTUAL_ENV" == "" ]]; then
        echo "âš ï¸  ä»®æƒ³ç’°å¢ƒãŒç„¡åŠ¹ã§ã™"
        echo "ä¿®å¾©: source .venv/bin/activate"
    else
        echo "âœ… ä»®æƒ³ç’°å¢ƒ: $VIRTUAL_ENV"
    fi
    
    # API ã‚­ãƒ¼ç¢ºèª
    if [[ -z "$OPENAI_API_KEY" ]] && [[ ! -f ".env" ]]; then
        echo "âŒ OpenAI API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
        echo "ä¿®å¾©: echo 'OPENAI_API_KEY=your_key' > .env"
        return 1
    fi
    
    # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç¢ºèª
    missing_packages=()
    required_packages=("openai" "langgraph" "langchain" "pydantic" "numpy" "pandas")
    
    for package in "${required_packages[@]}"; do
        if ! python -c "import $package" 2>/dev/null; then
            missing_packages+=("$package")
        fi
    done
    
    if [[ ${#missing_packages[@]} -gt 0 ]]; then
        echo "âŒ ä¸è¶³ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸: ${missing_packages[*]}"
        echo "ä¿®å¾©: pip install ${missing_packages[*]}"
        return 1
    fi
    
    echo "âœ… å…¨ä¾å­˜é–¢ä¿‚OK"
    
    # APIæ¥ç¶šãƒ†ã‚¹ãƒˆ
    if python -c "
import openai
try:
    client = openai.OpenAI()
    print('âœ… OpenAI APIæ¥ç¶šOK')
except Exception as e:
    print(f'âŒ APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}')
    exit(1)
" 2>/dev/null; then
        echo "âœ… APIæ¥ç¶šæ­£å¸¸"
    else
        echo "âŒ APIæ¥ç¶šã«å•é¡ŒãŒã‚ã‚Šã¾ã™"
        echo "ç¢ºèªäº‹é …:"
        echo "1. .envãƒ•ã‚¡ã‚¤ãƒ«ã®APIã‚­ãƒ¼"
        echo "2. ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶š"
        echo "3. OpenAIã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹"
        return 1
    fi
    
    echo "ğŸ‰ ç’°å¢ƒè¨ºæ–­å®Œäº† - å…¨ã¦æ­£å¸¸"
    return 0
}

# å®Ÿè¡Œ
check_and_fix_environment
```

### 2. ã‚¨ãƒ©ãƒ¼åˆ¥å¯¾å‡¦æ³•

```python
# error_handler.py ã¨ã—ã¦ä¿å­˜
import sys
import traceback
import logging
from pathlib import Path

def setup_error_logging():
    """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è¨­å®š"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_dir / "system.log", encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    return logging.getLogger("MultiAgentSystem")

def handle_common_errors():
    """ä¸€èˆ¬çš„ãªã‚¨ãƒ©ãƒ¼ã®å‡¦ç†ã‚¬ã‚¤ãƒ‰"""
    
    error_solutions = {
        "ModuleNotFoundError": {
            "åŸå› ": "å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„",
            "è§£æ±ºæ³•": [
                "pip install <ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å>",
                "ä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–ç¢ºèª: source .venv/bin/activate", 
                "requirements.txt ã‹ã‚‰ã®ä¸€æ‹¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install -r requirements.txt"
            ]
        },
        "OpenAI API Error": {
            "åŸå› ": "APIã‚­ãƒ¼ã¾ãŸã¯æ¥ç¶šã®å•é¡Œ",
            "è§£æ±ºæ³•": [
                ".envãƒ•ã‚¡ã‚¤ãƒ«ã§APIã‚­ãƒ¼ç¢ºèª",
                "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šç¢ºèª",
                "OpenAIã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ç¢ºèª: https://status.openai.com/",
                "APIã‚¯ã‚©ãƒ¼ã‚¿æ®‹é‡ç¢ºèª"
            ]
        },
        "JSON Decode Error": {
            "åŸå› ": "LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è§£æå¤±æ•—",
            "è§£æ±ºæ³•": [
                "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¦‹ç›´ã—ï¼ˆJSONå½¢å¼è¦æ±‚ã®æ˜ç¢ºåŒ–ï¼‰",
                "temperatureå€¤ã®èª¿æ•´ï¼ˆ0.7ä»¥ä¸‹æ¨å¥¨ï¼‰",
                "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã®ç¢ºèª"
            ]
        },
        "Memory Error": {
            "åŸå› ": "ãƒ¡ãƒ¢ãƒªä¸è¶³",
            "è§£æ±ºæ³•": [
                "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ•°ã®å‰Šæ¸›",
                "å®Ÿé¨“ãƒ©ã‚¦ãƒ³ãƒ‰æ•°ã®å‰Šæ¸›",
                "ãƒãƒƒãƒã‚µã‚¤ã‚ºã®èª¿æ•´",
                "ä¸è¦ãªå¤‰æ•°ã®ã‚¯ãƒªã‚¢: del variable"
            ]
        },
        "File Not Found": {
            "åŸå› ": "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å•é¡Œ",
            "è§£æ±ºæ³•": [
                "ç›¸å¯¾ãƒ‘ã‚¹ã‹ã‚‰çµ¶å¯¾ãƒ‘ã‚¹ã¸ã®å¤‰æ›´",
                "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå­˜åœ¨ç¢ºèª: mkdir -p results/",
                "ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™ç¢ºèª: chmod 644 <ãƒ•ã‚¡ã‚¤ãƒ«>"
            ]
        }
    }
    
    print("ğŸ”§ ä¸€èˆ¬çš„ãªã‚¨ãƒ©ãƒ¼ã¨è§£æ±ºæ³•:")
    for error_type, info in error_solutions.items():
        print(f"\nâŒ {error_type}")
        print(f"   åŸå› : {info['åŸå› ']}")
        print(f"   è§£æ±ºæ³•:")
        for i, solution in enumerate(info['è§£æ±ºæ³•'], 1):
            print(f"     {i}. {solution}")

def safe_experiment_runner(experiment_func, *args, **kwargs):
    """å®‰å…¨ãªå®Ÿé¨“å®Ÿè¡Œãƒ©ãƒƒãƒ‘ãƒ¼"""
    logger = setup_error_logging()
    
    try:
        logger.info(f"å®Ÿé¨“é–‹å§‹: {experiment_func.__name__}")
        result = experiment_func(*args, **kwargs)
        logger.info(f"å®Ÿé¨“å®Œäº†: {experiment_func.__name__}")
        return result
        
    except ImportError as e:
        logger.error(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print(f"\nâŒ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¸è¶³:")
        print(f"   ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"   è§£æ±ºæ³•: pip install {str(e).split()[-1]}")
        
    except FileNotFoundError as e:
        logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹: {e}")
        print(f"\nâŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:")
        print(f"   ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"   è§£æ±ºæ³•: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¨å­˜åœ¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        
    except Exception as e:
        logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯: {traceback.format_exc()}")
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:")
        print(f"   ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"   è©³ç´°: logs/system.log ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        
    return None

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    handle_common_errors()
```

### 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

```python
# performance_optimizer.py ã¨ã—ã¦ä¿å­˜
import time
import psutil
import gc
from memory_profiler import profile
from functools import wraps

def performance_monitor(func):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        # é–‹å§‹æ™‚ãƒ¡ãƒ¢ãƒª
        process = psutil.Process()
        start_memory = process.memory_info().rss / 1024 / 1024  # MB
        start_time = time.time()
        
        print(f"ğŸš€ {func.__name__} é–‹å§‹")
        print(f"   é–‹å§‹æ™‚ãƒ¡ãƒ¢ãƒª: {start_memory:.1f} MB")
        
        try:
            result = func(*args, **kwargs)
            
            # çµ‚äº†æ™‚ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            end_time = time.time()
            end_memory = process.memory_info().rss / 1024 / 1024
            execution_time = end_time - start_time
            memory_used = end_memory - start_memory
            
            print(f"âœ… {func.__name__} å®Œäº†")
            print(f"   å®Ÿè¡Œæ™‚é–“: {execution_time:.2f} ç§’")
            print(f"   ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_used:+.1f} MB")
            print(f"   æœ€çµ‚ãƒ¡ãƒ¢ãƒª: {end_memory:.1f} MB")
            
            return result
            
        except Exception as e:
            print(f"âŒ {func.__name__} ã‚¨ãƒ©ãƒ¼: {e}")
            raise
            
    return wrapper

def optimize_memory_usage():
    """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æœ€é©åŒ–"""
    print("ğŸ§¹ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œä¸­...")
    
    # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å¼·åˆ¶å®Ÿè¡Œ
    collected = gc.collect()
    print(f"   ğŸ—‘ï¸  å›åã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ: {collected}")
    
    # ãƒ¡ãƒ¢ãƒªçŠ¶æ³ç¢ºèª
    memory = psutil.virtual_memory()
    print(f"   ğŸ’¾ ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {memory.percent:.1f}%")
    print(f"   ğŸ’¾ åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª: {memory.available / 1024 / 1024:.1f} MB")

def get_system_recommendations():
    """ã‚·ã‚¹ãƒ†ãƒ æ¨å¥¨è¨­å®š"""
    memory = psutil.virtual_memory()
    cpu_count = psutil.cpu_count()
    
    recommendations = {
        "max_agents": min(20, cpu_count * 2),
        "max_rounds": min(50, int(memory.total / 1024 / 1024 / 100)),  # ãƒ¡ãƒ¢ãƒª(MB)/100
        "batch_size": min(10, cpu_count),
        "parallel_experiments": min(4, cpu_count)
    }
    
    print("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ æ¨å¥¨è¨­å®š:")
    for param, value in recommendations.items():
        print(f"   {param}: {value}")
    
    if memory.percent > 80:
        print("âš ï¸  ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„ã§ã™ï¼ˆ80%è¶…ï¼‰")
        print("   æ¨å¥¨: ã‚ˆã‚Šå°è¦æ¨¡ãªå®Ÿé¨“è¨­å®šã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„")
    
    if cpu_count < 4:
        print("âš ï¸  CPUæ•°ãŒå°‘ãªã„ã§ã™")
        print("   æ¨å¥¨: ä¸¦åˆ—å®Ÿé¨“æ•°ã‚’åˆ¶é™ã—ã¦ãã ã•ã„")
    
    return recommendations

# ä½¿ç”¨ä¾‹ã®é–¢æ•°ã«ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿é©ç”¨
@performance_monitor
def optimized_experiment_example():
    """æœ€é©åŒ–ã•ã‚ŒãŸå®Ÿé¨“ä¾‹"""
    import time
    
    # ã‚·ã‚¹ãƒ†ãƒ æ¨å¥¨è¨­å®šå–å¾—
    recommendations = get_system_recommendations()
    
    # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
    optimize_memory_usage()
    
    # æ¨¡æ“¬å®Ÿé¨“
    print("ğŸ§ª æœ€é©åŒ–å®Ÿé¨“å®Ÿè¡Œä¸­...")
    time.sleep(2)  # å®Ÿéš›ã®å‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    
    print("âœ… å®Ÿé¨“å®Œäº†")
    return {"status": "success"}

if __name__ == "__main__":
    optimized_experiment_example()
```

ã“ã®å®Œå…¨ã‚¬ã‚¤ãƒ‰ã«ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ä»¥ä¸‹ã®ã“ã¨ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ï¼š

### âœ… å®Ÿç¾å¯èƒ½ãªä½¿ç”¨æ–¹æ³•

1. **åŸºæœ¬å®Ÿé¨“å®Ÿè¡Œ**: æ—¥æœ¬èªLLMå®Ÿé¨“ã‹ã‚‰ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¾ã§
2. **ã‚«ã‚¹ã‚¿ãƒ å®Ÿé¨“ä½œæˆ**: ç‹¬è‡ªã®æ€§æ ¼ãƒ»ã‚²ãƒ¼ãƒ ãƒ»åˆ†ææ–¹æ³•
3. **çµæœåˆ†æ**: åŒ…æ‹¬çš„ãªçµ±è¨ˆåˆ†æã¨å¯è¦–åŒ–
4. **ã‚·ã‚¹ãƒ†ãƒ æ‹¡å¼µ**: æ–°ã—ã„ã‚²ãƒ¼ãƒ ã‚¿ã‚¤ãƒ—ã‚„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…
5. **ãƒˆãƒ©ãƒ–ãƒ«è§£æ±º**: ä¸€èˆ¬çš„ãªå•é¡Œã®è¨ºæ–­ã¨ä¿®å¾©

### ğŸ¯ ç ”ç©¶æ´»ç”¨ä¾¡å€¤

ã“ã®ä½¿ç”¨æ–¹æ³•ã‚¬ã‚¤ãƒ‰ã«ã‚ˆã‚Šã€ä¿®å£«ç ”ç©¶ã€Œé€²åŒ–çš„ç¾¤çŸ¥èƒ½ã«åŸºã¥ãLoRAã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé›†å›£ã®å”èª¿çš„æœ€é©åŒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ã®å®Œå…¨ãªå®Ÿé¨“ç’°å¢ƒãŒåˆ©ç”¨å¯èƒ½ã«ãªã‚Šã¾ã—ãŸã€‚