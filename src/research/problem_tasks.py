#!/usr/bin/env python3
"""
è¤‡é›‘å•é¡Œè§£æ±ºã‚¿ã‚¹ã‚¯å®šç¾©ã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ 

ä¿®å£«ç ”ç©¶ç”¨ã®é«˜åº¦ãªå•é¡Œè§£æ±ºã‚¿ã‚¹ã‚¯ã¨ãã®è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import asyncio
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from abc import ABC, abstractmethod


class TaskComplexity(Enum):
    """ã‚¿ã‚¹ã‚¯è¤‡é›‘åº¦"""
    BASIC = "basic"           # åŸºç¤ãƒ¬ãƒ™ãƒ«
    INTERMEDIATE = "intermediate"  # ä¸­ç´šãƒ¬ãƒ™ãƒ«
    ADVANCED = "advanced"     # é«˜åº¦ãƒ¬ãƒ™ãƒ«
    EXPERT = "expert"         # å°‚é–€å®¶ãƒ¬ãƒ™ãƒ«


class TaskCategory(Enum):
    """ã‚¿ã‚¹ã‚¯ã‚«ãƒ†ã‚´ãƒª"""
    MULTI_PERSPECTIVE = "multi_perspective"     # å¤šé¢çš„åˆ†æ
    CREATIVE_DESIGN = "creative_design"         # å‰µç™ºçš„è¨­è¨ˆ
    STRATEGIC_PLANNING = "strategic_planning"   # æˆ¦ç•¥ç­–å®š
    OPTIMIZATION = "optimization"               # æœ€é©åŒ–
    INTERDISCIPLINARY = "interdisciplinary"     # å­¦éš›çš„


@dataclass
class SolutionQuality:
    """è§£æ±ºç­–å“è³ªè©•ä¾¡"""
    originality: float          # ç‹¬å‰µæ€§ (0-1)
    feasibility: float         # å®Ÿç¾å¯èƒ½æ€§ (0-1)
    comprehensiveness: float   # åŒ…æ‹¬æ€§ (0-1)
    logical_consistency: float # è«–ç†çš„ä¸€è²«æ€§ (0-1)
    innovation: float          # é©æ–°æ€§ (0-1)
    practical_value: float     # å®Ÿç”¨ä¾¡å€¤ (0-1)
    
    @property
    def overall_score(self) -> float:
        """ç·åˆã‚¹ã‚³ã‚¢"""
        return (self.originality + self.feasibility + self.comprehensiveness + 
                self.logical_consistency + self.innovation + self.practical_value) / 6


@dataclass
class CollaborationMetrics:
    """å”èª¿ãƒ—ãƒ­ã‚»ã‚¹è©•ä¾¡"""
    knowledge_sharing_efficiency: float  # çŸ¥è­˜å…±æœ‰åŠ¹ç‡
    consensus_building_speed: float     # åˆæ„å½¢æˆé€Ÿåº¦
    emergent_insights: int              # å‰µç™ºçš„æ´å¯Ÿæ•°
    agent_satisfaction: float           # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæº€è¶³åº¦
    communication_quality: float        # ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³å“è³ª
    conflict_resolution: float          # å¯¾ç«‹è§£æ±ºèƒ½åŠ›


@dataclass
class ProblemTask:
    """å•é¡Œè§£æ±ºã‚¿ã‚¹ã‚¯"""
    task_id: str
    title: str
    description: str
    complexity: TaskComplexity
    category: TaskCategory
    expected_solution_aspects: List[str]  # æœŸå¾…ã•ã‚Œã‚‹è§£æ±ºç­–ã®å´é¢
    evaluation_criteria: Dict[str, float]  # è©•ä¾¡åŸºæº–ã¨é‡ã¿
    time_limit_minutes: int = 60
    max_agents: int = 6
    required_expertise: List[str] = field(default_factory=list)
    
    def to_prompt(self) -> str:
        """ã‚¿ã‚¹ã‚¯ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå½¢å¼ã«å¤‰æ›"""
        prompt = f"""
## å•é¡Œè§£æ±ºã‚¿ã‚¹ã‚¯: {self.title}

### å•é¡Œèª¬æ˜
{self.description}

### æ±‚ã‚ã‚‰ã‚Œã‚‹è§£æ±ºç­–ã®è¦ç´ 
{chr(10).join(f'- {aspect}' for aspect in self.expected_solution_aspects)}

### åˆ¶ç´„æ¡ä»¶
- åˆ¶é™æ™‚é–“: {self.time_limit_minutes}åˆ†
- è¤‡é›‘åº¦: {self.complexity.value}
- ã‚«ãƒ†ã‚´ãƒª: {self.category.value}

### å¿…è¦ãªå°‚é–€çŸ¥è­˜
{chr(10).join(f'- {expertise}' for expertise in self.required_expertise) if self.required_expertise else '- ç‰¹ã«ãªã—'}

ã‚ãªãŸã¯ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨å”åŠ›ã—ã¦ã€ã“ã®å•é¡Œã«å¯¾ã™ã‚‹æœ€é©ãªè§£æ±ºç­–ã‚’è¦‹ã¤ã‘ã¦ãã ã•ã„ã€‚
"""
        return prompt


class ProblemTaskLibrary:
    """å•é¡Œè§£æ±ºã‚¿ã‚¹ã‚¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒª"""
    
    def __init__(self):
        self.tasks = self._initialize_tasks()
    
    def _initialize_tasks(self) -> Dict[str, ProblemTask]:
        """ã‚¿ã‚¹ã‚¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®åˆæœŸåŒ–"""
        tasks = {}
        
        # åŸºç¤ãƒ¬ãƒ™ãƒ«ã‚¿ã‚¹ã‚¯
        tasks["sustainable_city"] = ProblemTask(
            task_id="sustainable_city",
            title="æŒç¶šå¯èƒ½ãªæœªæ¥éƒ½å¸‚ã®è¨­è¨ˆ",
            description="""
2050å¹´ã®äººå£50ä¸‡äººã®æ–°éƒ½å¸‚ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚ã“ã®éƒ½å¸‚ã¯ç’°å¢ƒè² è·ã‚’æœ€å°é™ã«æŠ‘ãˆãªãŒã‚‰ã€
ä½æ°‘ã®ç”Ÿæ´»ã®è³ªã‚’æœ€å¤§åŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

è€ƒæ…®ã™ã¹ãè¦ç´ ï¼š
- ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¾›çµ¦ï¼ˆå†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼‰
- äº¤é€šã‚·ã‚¹ãƒ†ãƒ ï¼ˆå…¬å…±äº¤é€šã€è‡ªå‹•é‹è»¢ï¼‰
- ä½å®…ãƒ»å•†æ¥­ãƒ»å·¥æ¥­ã®é…ç½®
- å»ƒæ£„ç‰©ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
- ç·‘åœ°ãƒ»å…¬åœ’ã®é…ç½®
- ç½å®³å¯¾ç­–ï¼ˆåœ°éœ‡ã€å°é¢¨ã€æ´ªæ°´ï¼‰
- é«˜é½¢åŒ–ç¤¾ä¼šã¸ã®å¯¾å¿œ
- ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–ãƒ»ã‚¹ãƒãƒ¼ãƒˆã‚·ãƒ†ã‚£è¦ç´ 
            """,
            complexity=TaskComplexity.INTERMEDIATE,
            category=TaskCategory.STRATEGIC_PLANNING,
            expected_solution_aspects=[
                "éƒ½å¸‚å…¨ä½“ã®ãƒã‚¹ã‚¿ãƒ¼ãƒ—ãƒ©ãƒ³",
                "ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¾›çµ¦æˆ¦ç•¥",
                "äº¤é€šã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ",
                "ç’°å¢ƒè² è·å‰Šæ¸›ç­–",
                "ç¤¾ä¼šã‚¤ãƒ³ãƒ•ãƒ©è¨ˆç”»",
                "çµŒæ¸ˆçš„æŒç¶šå¯èƒ½æ€§"
            ],
            evaluation_criteria={
                "å‰µé€ æ€§": 0.2,
                "å®Ÿç¾å¯èƒ½æ€§": 0.25,
                "ç’°å¢ƒé…æ…®": 0.2,
                "ç¤¾ä¼šçš„ä¾¡å€¤": 0.2,
                "çµŒæ¸ˆæ€§": 0.15
            },
            time_limit_minutes=90,
            required_expertise=["éƒ½å¸‚è¨ˆç”»", "ç’°å¢ƒå·¥å­¦", "çµŒæ¸ˆå­¦", "ç¤¾ä¼šå­¦"]
        )
        
        tasks["ai_ethics_framework"] = ProblemTask(
            task_id="ai_ethics_framework",
            title="AIé–‹ç™ºå€«ç†ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ç­–å®š",
            description="""
æ€¥é€Ÿã«ç™ºå±•ã™ã‚‹AIæŠ€è¡“ã«å¯¾å¿œã—ãŸåŒ…æ‹¬çš„ãªå€«ç†ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç­–å®šã—ã¦ãã ã•ã„ã€‚
ã“ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã¯ä¼æ¥­ã€ç ”ç©¶æ©Ÿé–¢ã€æ”¿åºœæ©Ÿé–¢ã§æ´»ç”¨ã•ã‚Œã€AIé–‹ç™ºã¨é‹ç”¨ã®
å€«ç†çš„åŸºæº–ã‚’æä¾›ã—ã¾ã™ã€‚

å¯¾è±¡ã¨ãªã‚‹AIæŠ€è¡“ï¼š
- ç”ŸæˆAIï¼ˆLarge Language Modelsï¼‰
- ç”»åƒãƒ»å‹•ç”»ç”ŸæˆAI
- è‡ªå‹•é‹è»¢ã‚·ã‚¹ãƒ†ãƒ 
- åŒ»ç™‚è¨ºæ–­AI
- äººäº‹ãƒ»æ¡ç”¨AI
- ç›£è¦–ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£AI

è€ƒæ…®ã™ã¹ãå•é¡Œï¼š
- ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·
- ãƒã‚¤ã‚¢ã‚¹ãƒ»å·®åˆ¥ã®é˜²æ­¢
- é€æ˜æ€§ãƒ»èª¬æ˜å¯èƒ½æ€§
- äººé–“ã®è‡ªå¾‹æ€§ã®å°Šé‡
- è²¬ä»»ã®æ‰€åœ¨
- ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªæ–‡åŒ–çš„å·®ç•°
            """,
            complexity=TaskComplexity.ADVANCED,
            category=TaskCategory.INTERDISCIPLINARY,
            expected_solution_aspects=[
                "åŸºæœ¬åŸå‰‡ã¨ä¾¡å€¤è¦³",
                "æŠ€è¡“åˆ†é‡åˆ¥ã®å…·ä½“çš„ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³",
                "å®Ÿè£…ãƒ»ç›£æŸ»æ‰‹é †",
                "é•åæ™‚ã®å¯¾å¿œãƒ—ãƒ­ã‚»ã‚¹",
                "å›½éš›å”èª¿ã®æ çµ„ã¿",
                "ç¶™ç¶šçš„æ›´æ–°ãƒ¡ã‚«ãƒ‹ã‚ºãƒ "
            ],
            evaluation_criteria={
                "åŒ…æ‹¬æ€§": 0.25,
                "å®Ÿç”¨æ€§": 0.2,
                "æ–‡åŒ–çš„é…æ…®": 0.15,
                "æŠ€è¡“çš„ç†è§£": 0.2,
                "å°†æ¥æ€§": 0.2
            },
            time_limit_minutes=120,
            required_expertise=["AIæŠ€è¡“", "å€«ç†å­¦", "æ³•å­¦", "ç¤¾ä¼šå­¦", "å›½éš›é–¢ä¿‚"]
        )
        
        tasks["pandemic_response"] = ProblemTask(
            task_id="pandemic_response",
            title="æ¬¡ä¸–ä»£ãƒ‘ãƒ³ãƒ‡ãƒŸãƒƒã‚¯å¯¾å¿œæˆ¦ç•¥",
            description="""
COVID-19ã®çµŒé¨“ã‚’è¸ã¾ãˆã€å°†æ¥ã®ãƒ‘ãƒ³ãƒ‡ãƒŸãƒƒã‚¯ã«å¯¾ã™ã‚‹åŒ…æ‹¬çš„ãªå¯¾å¿œæˆ¦ç•¥ã‚’
ç­–å®šã—ã¦ãã ã•ã„ã€‚ã“ã®æˆ¦ç•¥ã¯å›½ã€åœ°æ–¹è‡ªæ²»ä½“ã€åŒ»ç™‚æ©Ÿé–¢ã€ä¼æ¥­ã€å€‹äººã®
å„ãƒ¬ãƒ™ãƒ«ã§ã®å¯¾å¿œã‚’å«ã¿ã¾ã™ã€‚

è€ƒæ…®ã™ã¹ãè¦ç´ ï¼š
- æ—©æœŸè­¦æˆ’ãƒ»ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
- åŒ»ç™‚ä½“åˆ¶ã®æ‹¡å¼µæ€§
- ãƒ¯ã‚¯ãƒãƒ³ãƒ»æ²»ç™‚è–¬ã®è¿…é€Ÿé–‹ç™º
- ç¤¾ä¼šæ©Ÿèƒ½ã®ç¶™ç¶šï¼ˆBCPï¼‰
- çµŒæ¸ˆæ”¯æ´æ”¿ç­–
- å›½éš›å”èª¿ãƒ»æƒ…å ±å…±æœ‰
- ãƒ‡ã‚¸ã‚¿ãƒ«æŠ€è¡“ã®æ´»ç”¨
- ç¤¾ä¼šã®åˆ†æ–­ãƒ»æ ¼å·®ã¸ã®å¯¾å¿œ
- ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹å¯¾ç­–
            """,
            complexity=TaskComplexity.EXPERT,
            category=TaskCategory.STRATEGIC_PLANNING,
            expected_solution_aspects=[
                "æ®µéšåˆ¥å¯¾å¿œæˆ¦ç•¥",
                "åŒ»ç™‚ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ",
                "çµŒæ¸ˆæ”¿ç­–ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸",
                "æŠ€è¡“æ´»ç”¨æˆ¦ç•¥",
                "å›½éš›å”èª¿æ çµ„ã¿",
                "ç¤¾ä¼šçš„é…æ…®æ–¹é‡"
            ],
            evaluation_criteria={
                "ç§‘å­¦çš„æ ¹æ‹ ": 0.25,
                "å®Ÿè£…å¯èƒ½æ€§": 0.2,
                "ç¤¾ä¼šçš„å…¬å¹³æ€§": 0.2,
                "çµŒæ¸ˆçš„æŒç¶šæ€§": 0.15,
                "å›½éš›å”èª¿": 0.2
            },
            time_limit_minutes=150,
            required_expertise=["å…¬è¡†è¡›ç”Ÿ", "åŒ»å­¦", "çµŒæ¸ˆå­¦", "æ”¿ç­–å­¦", "ç¤¾ä¼šå­¦", "å›½éš›é–¢ä¿‚"]
        )
        
        # ä¸­ç´šãƒ¬ãƒ™ãƒ«ã‚¿ã‚¹ã‚¯
        tasks["remote_work_future"] = ProblemTask(
            task_id="remote_work_future",
            title="ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯æ™‚ä»£ã®çµ„ç¹”è¨­è¨ˆ",
            description="""
ã‚³ãƒ­ãƒŠç¦ã‚’çµŒã¦å®šç€ã—ãŸãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å‰æã¨ã—ãŸã€æ–°ã—ã„çµ„ç¹”ã®ã‚ã‚Šæ–¹ã‚’
è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚å¾“æ¥ã®ã‚ªãƒ•ã‚£ã‚¹ä¸­å¿ƒã®çµ„ç¹”ã‹ã‚‰ã€å ´æ‰€ã«ä¾å­˜ã—ãªã„
åŠ¹ç‡çš„ã§å‰µé€ çš„ãªçµ„ç¹”ã¸ã®è»¢æ›ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚

æ¤œè¨äº‹é …ï¼š
- çµ„ç¹”æ§‹é€ ãƒ»éšå±¤ã®è¦‹ç›´ã—
- ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ–¹æ³•ã®æœ€é©åŒ–
- è©•ä¾¡ãƒ»äººäº‹ã‚·ã‚¹ãƒ†ãƒ ã®å¤‰æ›´
- ä¼æ¥­æ–‡åŒ–ã®ç¶­æŒãƒ»ç™ºå±•
- æ–°äººæ•™è‚²ãƒ»OJTã®æ–¹æ³•
- ãƒãƒ¼ãƒ ãƒ“ãƒ«ãƒ‡ã‚£ãƒ³ã‚°
- ãƒ¯ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ•ãƒãƒ©ãƒ³ã‚¹
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹
            """,
            complexity=TaskComplexity.BASIC,
            category=TaskCategory.MULTI_PERSPECTIVE,
            expected_solution_aspects=[
                "æ–°çµ„ç¹”æ§‹é€ ã®ææ¡ˆ",
                "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥",
                "äººäº‹è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ",
                "ä¼æ¥­æ–‡åŒ–ç¶™æ‰¿æ–¹æ³•",
                "æŠ€è¡“åŸºç›¤è¦ä»¶",
                "å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—"
            ],
            evaluation_criteria={
                "å®Ÿç”¨æ€§": 0.3,
                "å¾“æ¥­å“¡æº€è¶³åº¦": 0.25,
                "ç”Ÿç”£æ€§å‘ä¸Š": 0.2,
                "ã‚³ã‚¹ãƒˆåŠ¹ç‡": 0.15,
                "é©æ–°æ€§": 0.1
            },
            time_limit_minutes=60,
            required_expertise=["çµ„ç¹”è«–", "äººäº‹ç®¡ç†", "ITæŠ€è¡“", "å¿ƒç†å­¦"]
        )
        
        tasks["circular_economy"] = ProblemTask(
            task_id="circular_economy",
            title="å¾ªç’°çµŒæ¸ˆãƒ“ã‚¸ãƒã‚¹ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆ",
            description="""
å¾“æ¥ã®ã€Œä½œã‚‹â†’ä½¿ã†â†’æ¨ã¦ã‚‹ã€ã®ç·šå½¢çµŒæ¸ˆã‹ã‚‰ã€ã€Œå¾ªç’°å‹çµŒæ¸ˆã€ã¸ã®è»¢æ›ã‚’
å®Ÿç¾ã™ã‚‹ãƒ“ã‚¸ãƒã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚ç‰¹å®šã®æ¥­ç•Œï¼ˆä¾‹ï¼šãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ã€
é›»å­æ©Ÿå™¨ã€é£Ÿå“ï¼‰ã‚’é¸æŠã—ã€å…·ä½“çš„ãªå¾ªç’°å‹ãƒ“ã‚¸ãƒã‚¹ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

å¾ªç’°çµŒæ¸ˆã®è¦ç´ ï¼š
- è¨­è¨ˆæ®µéšã§ã®å¾ªç’°æ€§è€ƒæ…®
- é•·å¯¿å‘½åŒ–ãƒ»ä¿®ç†å¯èƒ½æ€§
- ã‚·ã‚§ã‚¢ãƒªãƒ³ã‚°ãƒ»ã‚µãƒ¼ãƒ“ã‚¹åŒ–
- å†åˆ©ç”¨ãƒ»ãƒªã‚µã‚¤ã‚¯ãƒ«
- ãƒã‚¤ã‚ªåˆ†è§£ãƒ»å†ç”Ÿææ–™
- ãƒ‡ã‚¸ã‚¿ãƒ«æŠ€è¡“æ´»ç”¨
- ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼å”åŠ›
- çµŒæ¸ˆçš„ã‚¤ãƒ³ã‚»ãƒ³ãƒ†ã‚£ãƒ–
            """,
            complexity=TaskComplexity.INTERMEDIATE,
            category=TaskCategory.CREATIVE_DESIGN,
            expected_solution_aspects=[
                "ãƒ“ã‚¸ãƒã‚¹ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆ",
                "ãƒãƒªãƒ¥ãƒ¼ãƒã‚§ãƒ¼ãƒ³å†æ§‹ç¯‰",
                "åç›Šãƒ¢ãƒ‡ãƒ«",
                "ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã‚·ãƒƒãƒ—æˆ¦ç•¥",
                "æŠ€è¡“ãƒ»ã‚¤ãƒ³ãƒ•ãƒ©è¦ä»¶",
                "ç§»è¡Œè¨ˆç”»"
            ],
            evaluation_criteria={
                "ç’°å¢ƒã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ": 0.25,
                "çµŒæ¸ˆçš„æŒç¶šæ€§": 0.25,
                "å®Ÿç¾å¯èƒ½æ€§": 0.2,
                "ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£": 0.15,
                "ç¤¾ä¼šçš„ä¾¡å€¤": 0.15
            },
            time_limit_minutes=75,
            required_expertise=["ãƒ“ã‚¸ãƒã‚¹æˆ¦ç•¥", "ç’°å¢ƒå­¦", "ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³", "æŠ€è¡“çµŒå–¶"]
        )
        
        # é«˜åº¦ãƒ¬ãƒ™ãƒ«ã‚¿ã‚¹ã‚¯
        tasks["space_colonization"] = ProblemTask(
            task_id="space_colonization",
            title="ç«æ˜Ÿã‚³ãƒ­ãƒ‹ãƒ¼å»ºè¨­è¨ˆç”»",
            description="""
2040å¹´ä»£ã«å®Ÿç¾å¯èƒ½ãªç«æ˜Ÿã¸ã®äººé¡å±…ä½ã‚³ãƒ­ãƒ‹ãƒ¼ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚
1000äººè¦æ¨¡ã®æŒç¶šå¯èƒ½ãªã‚³ãƒ­ãƒ‹ãƒ¼ã‚’æƒ³å®šã—ã€æŠ€è¡“çš„ãƒ»ç¤¾ä¼šçš„ãƒ»å€«ç†çš„
å´é¢ã‚’åŒ…æ‹¬çš„ã«æ¤œè¨ã—ã¦ãã ã•ã„ã€‚

æŠ€è¡“çš„èª²é¡Œï¼š
- ç”Ÿå‘½ç¶­æŒã‚·ã‚¹ãƒ†ãƒ ï¼ˆé…¸ç´ ã€æ°´ã€é£Ÿæ–™ï¼‰
- ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¾›çµ¦
- å»ºè¨­è³‡æã¨å·¥æ³•
- é€šä¿¡ã‚·ã‚¹ãƒ†ãƒ 
- åŒ»ç™‚ã‚·ã‚¹ãƒ†ãƒ 
- äº¤é€šãƒ»è¼¸é€

ç¤¾ä¼šçš„èª²é¡Œï¼š
- ã‚¬ãƒãƒŠãƒ³ã‚¹ãƒ»æ³•åˆ¶åº¦
- çµŒæ¸ˆã‚·ã‚¹ãƒ†ãƒ 
- æ•™è‚²ãƒ»æ–‡åŒ–ç¶™æ‰¿
- å¿ƒç†çš„ã‚±ã‚¢
- åœ°çƒã¨ã®é–¢ä¿‚
- ç«æ˜Ÿå›ºæœ‰ã®ç¤¾ä¼šå½¢æˆ
            """,
            complexity=TaskComplexity.EXPERT,
            category=TaskCategory.INTERDISCIPLINARY,
            expected_solution_aspects=[
                "æŠ€è¡“ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ",
                "ç¤¾ä¼šåˆ¶åº¦è¨­è¨ˆ",
                "å»ºè¨­ãƒ»å±•é–‹è¨ˆç”»",
                "ãƒªã‚¹ã‚¯ç®¡ç†æˆ¦ç•¥",
                "åœ°çƒã¨ã®é–¢ä¿‚æ€§",
                "é•·æœŸæŒç¶šå¯èƒ½æ€§"
            ],
            evaluation_criteria={
                "æŠ€è¡“çš„å®Ÿç¾æ€§": 0.25,
                "ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ": 0.2,
                "ç¤¾ä¼šçš„æŒç¶šæ€§": 0.2,
                "ãƒªã‚¹ã‚¯å¯¾å¿œ": 0.2,
                "é©æ–°æ€§": 0.15
            },
            time_limit_minutes=180,
            required_expertise=["å®‡å®™å·¥å­¦", "ç”Ÿå‘½ç§‘å­¦", "ç¤¾ä¼šå­¦", "å¿ƒç†å­¦", "æ”¿æ²»å­¦", "çµŒæ¸ˆå­¦"]
        )
        
        return tasks
    
    def get_task(self, task_id: str) -> Optional[ProblemTask]:
        """ã‚¿ã‚¹ã‚¯å–å¾—"""
        return self.tasks.get(task_id)
    
    def get_tasks_by_complexity(self, complexity: TaskComplexity) -> List[ProblemTask]:
        """è¤‡é›‘åº¦åˆ¥ã‚¿ã‚¹ã‚¯å–å¾—"""
        return [task for task in self.tasks.values() if task.complexity == complexity]
    
    def get_tasks_by_category(self, category: TaskCategory) -> List[ProblemTask]:
        """ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚¿ã‚¹ã‚¯å–å¾—"""
        return [task for task in self.tasks.values() if task.category == category]
    
    def list_all_tasks(self) -> List[ProblemTask]:
        """å…¨ã‚¿ã‚¹ã‚¯ä¸€è¦§"""
        return list(self.tasks.values())


class SolutionEvaluator:
    """è§£æ±ºç­–è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        pass
    
    async def evaluate_solution(self, task: ProblemTask, solution: str, 
                              process_metrics: CollaborationMetrics) -> Tuple[SolutionQuality, Dict[str, Any]]:
        """è§£æ±ºç­–ã®åŒ…æ‹¬çš„è©•ä¾¡"""
        
        # LLMã‚’ä½¿ç”¨ã—ãŸå“è³ªè©•ä¾¡ï¼ˆå®Ÿè£…æ™‚ï¼‰
        quality = await self._evaluate_solution_quality(task, solution)
        
        # è©³ç´°åˆ†æ
        detailed_analysis = {
            "task_coverage": await self._analyze_task_coverage(task, solution),
            "innovation_aspects": await self._identify_innovations(solution),
            "potential_risks": await self._assess_risks(solution),
            "implementation_challenges": await self._analyze_implementation(solution),
            "stakeholder_impact": await self._analyze_stakeholder_impact(solution)
        }
        
        return quality, detailed_analysis
    
    async def _evaluate_solution_quality(self, task: ProblemTask, solution: str) -> SolutionQuality:
        """è§£æ±ºç­–å“è³ªã®è©•ä¾¡"""
        # å®Ÿè£…æ™‚ã¯LLMã‚’ä½¿ç”¨ã—ãŸè©³ç´°è©•ä¾¡
        # ç¾åœ¨ã¯ä»®ã®å®Ÿè£…
        return SolutionQuality(
            originality=0.7,
            feasibility=0.8,
            comprehensiveness=0.75,
            logical_consistency=0.85,
            innovation=0.65,
            practical_value=0.8
        )
    
    async def _analyze_task_coverage(self, task: ProblemTask, solution: str) -> Dict[str, float]:
        """ã‚¿ã‚¹ã‚¯è¦æ±‚äº‹é …ã®ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ"""
        coverage = {}
        for aspect in task.expected_solution_aspects:
            # å®Ÿè£…æ™‚ã¯LLMãƒ™ãƒ¼ã‚¹ã®åˆ†æ
            coverage[aspect] = 0.8  # ä»®ã®å€¤
        return coverage
    
    async def _identify_innovations(self, solution: str) -> List[str]:
        """é©æ–°çš„è¦ç´ ã®ç‰¹å®š"""
        return ["æ–°æŠ€è¡“çµ±åˆ", "å‰µç™ºçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ"]  # ä»®ã®å®Ÿè£…
    
    async def _assess_risks(self, solution: str) -> List[Dict[str, Any]]:
        """ãƒªã‚¹ã‚¯åˆ†æ"""
        return [
            {"risk": "å®Ÿè£…å›°é›£æ€§", "severity": "medium", "mitigation": "æ®µéšçš„å®Ÿè£…"},
            {"risk": "ã‚³ã‚¹ãƒˆè¶…é", "severity": "low", "mitigation": "äºˆç®—ç®¡ç†å¼·åŒ–"}
        ]
    
    async def _analyze_implementation(self, solution: str) -> Dict[str, Any]:
        """å®Ÿè£…åˆ†æ"""
        return {
            "complexity": "high",
            "timeline": "2-3å¹´",
            "key_challenges": ["æŠ€è¡“çš„å®Ÿç¾æ€§", "ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼èª¿æ•´"],
            "success_factors": ["å¼·åŠ›ãªãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—", "ååˆ†ãªãƒªã‚½ãƒ¼ã‚¹"]
        }
    
    async def _analyze_stakeholder_impact(self, solution: str) -> Dict[str, Any]:
        """ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼å½±éŸ¿åˆ†æ"""
        return {
            "primary_beneficiaries": ["å¸‚æ°‘", "ä¼æ¥­"],
            "potential_concerns": ["ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼", "é›‡ç”¨ã¸ã®å½±éŸ¿"],
            "implementation_support": ["æ”¿åºœ", "å°‚é–€æ©Ÿé–¢"]
        }


class BenchmarkSystem:
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.task_library = ProblemTaskLibrary()
        self.evaluator = SolutionEvaluator()
        self.baseline_results = {}
    
    async def run_benchmark_suite(self, complexity_levels: List[TaskComplexity] = None) -> Dict[str, Any]:
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ"""
        if complexity_levels is None:
            complexity_levels = [TaskComplexity.BASIC, TaskComplexity.INTERMEDIATE]
        
        results = {
            "benchmark_id": f"benchmark_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "timestamp": datetime.now().isoformat(),
            "tasks_evaluated": [],
            "summary_metrics": {},
            "detailed_results": {}
        }
        
        for complexity in complexity_levels:
            tasks = self.task_library.get_tasks_by_complexity(complexity)
            for task in tasks:
                print(f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ: {task.title} ({complexity.value})")
                
                # å®Ÿéš›ã®å®Ÿè£…æ™‚ã¯å”èª¿ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè¡Œ
                # ç¾åœ¨ã¯ä»®ã®çµæœ
                task_result = {
                    "task_id": task.task_id,
                    "complexity": complexity.value,
                    "execution_time": 45.5,
                    "solution_quality": 0.75,
                    "collaboration_efficiency": 0.8
                }
                
                results["tasks_evaluated"].append(task_result)
                results["detailed_results"][task.task_id] = task_result
        
        # ã‚µãƒãƒªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        results["summary_metrics"] = self._calculate_summary_metrics(results["detailed_results"])
        
        return results
    
    def _calculate_summary_metrics(self, detailed_results: Dict[str, Any]) -> Dict[str, float]:
        """ã‚µãƒãƒªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
        if not detailed_results:
            return {}
        
        quality_scores = [r["solution_quality"] for r in detailed_results.values()]
        collaboration_scores = [r["collaboration_efficiency"] for r in detailed_results.values()]
        execution_times = [r["execution_time"] for r in detailed_results.values()]
        
        return {
            "avg_solution_quality": sum(quality_scores) / len(quality_scores),
            "avg_collaboration_efficiency": sum(collaboration_scores) / len(collaboration_scores),
            "avg_execution_time": sum(execution_times) / len(execution_times),
            "total_tasks": len(detailed_results),
            "success_rate": 1.0  # ä»®ã®å€¤
        }
    
    def compare_with_baseline(self, results: Dict[str, Any], baseline_type: str = "single_llm") -> Dict[str, Any]:
        """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ"""
        # å®Ÿè£…æ™‚ã¯ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³çµæœã¨æ¯”è¼ƒ
        return {
            "improvement_factor": 1.25,
            "quality_improvement": 0.15,
            "efficiency_improvement": 0.3,
            "areas_of_improvement": ["å‰µé€ æ€§", "åŒ…æ‹¬æ€§", "å®Ÿè£…å¯èƒ½æ€§"]
        }


# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆé–¢æ•°
async def demo_benchmark_system():
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢"""
    print("ğŸ§ª ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("=" * 60)
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    benchmark = BenchmarkSystem()
    
    # ã‚¿ã‚¹ã‚¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèª
    print("\nğŸ“š åˆ©ç”¨å¯èƒ½ãªã‚¿ã‚¹ã‚¯:")
    for task in benchmark.task_library.list_all_tasks():
        print(f"  - {task.title} ({task.complexity.value}, {task.category.value})")
    
    # ç‰¹å®šã‚¿ã‚¹ã‚¯ã®è©³ç´°è¡¨ç¤º
    print("\nğŸ¯ ã‚µãƒ³ãƒ—ãƒ«ã‚¿ã‚¹ã‚¯è©³ç´°:")
    sample_task = benchmark.task_library.get_task("sustainable_city")
    if sample_task:
        print(sample_task.to_prompt())
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œï¼ˆç°¡æ˜“ç‰ˆï¼‰
    print("\nğŸš€ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ:")
    results = await benchmark.run_benchmark_suite([TaskComplexity.BASIC])
    
    print(f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†: {len(results['tasks_evaluated'])}ã‚¿ã‚¹ã‚¯")
    print(f"å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {results['summary_metrics']['avg_solution_quality']:.3f}")
    print(f"å¹³å‡å”èª¿åŠ¹ç‡: {results['summary_metrics']['avg_collaboration_efficiency']:.3f}")
    
    return results


if __name__ == "__main__":
    asyncio.run(demo_benchmark_system())