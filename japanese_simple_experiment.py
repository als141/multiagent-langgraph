#!/usr/bin/env python3
"""
æ—¥æœ¬èªLLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿé¨“ï¼ˆç°¡æ˜“ç‰ˆï¼‰

OpenAI APIã‚’ä½¿ã£ãŸå®Ÿéš›ã®LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒå£«ã®æˆ¦ç•¥çš„ä¼šè©±å®Ÿé¨“
"""

import asyncio
import json
import os
from typing import Dict, List, Any
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
import openai
from openai import AsyncOpenAI


@dataclass
class LLMAgent:
    """LLMã‚’ä½¿ç”¨ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    agent_id: str
    name: str
    personality: Dict[str, Any]
    total_payoff: float = 0.0
    conversation_history: List = None
    
    def __post_init__(self):
        if self.conversation_history is None:
            self.conversation_history = []


class JapaneseLLMExperiment:
    """æ—¥æœ¬èªLLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿé¨“ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        # OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.client = AsyncOpenAI(api_key=api_key)
        
        # çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.results_dir = Path("results/japanese_llm_experiments")
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ€§æ ¼è¨­å®š
        self.personalities = {
            "å¤–äº¤å®˜_ç”°ä¸­": {
                "cooperation_tendency": 0.8,
                "risk_tolerance": 0.3,
                "trust_propensity": 0.7,
                "communication_style": "diplomatic",
                "description": "ç¤¼å„€æ­£ã—ãã€é•·æœŸçš„ãªé–¢ä¿‚ã‚’é‡è¦–ã™ã‚‹å”åŠ›çš„ãªå¤–äº¤å®˜",
                "catchphrase": "ãŠäº’ã„ã«ã¨ã£ã¦è‰¯ã„çµæœã‚’ç›®æŒ‡ã—ã¾ã—ã‚‡ã†"
            },
            "æ¥½è¦³ä¸»ç¾©è€…_ä½è—¤": {
                "cooperation_tendency": 0.9,
                "risk_tolerance": 0.6,
                "trust_propensity": 0.8,
                "communication_style": "optimistic",
                "description": "å‰å‘ãã§äººã‚’ä¿¡ã˜ã‚‹æ¥½è¦³çš„ãªæ€§æ ¼",
                "catchphrase": "ãã£ã¨ã†ã¾ãã„ãã¾ã™ã‚ˆï¼"
            },
            "æˆ¦ç•¥å®¶_éˆ´æœ¨": {
                "cooperation_tendency": 0.4,
                "risk_tolerance": 0.7,
                "trust_propensity": 0.4,
                "communication_style": "analytical",
                "description": "å†·é™ã§è¨ˆç®—é«˜ã„ã€åˆ©ç›Šã‚’é‡è¦–ã™ã‚‹æˆ¦ç•¥å®¶",
                "catchphrase": "æ•°å­—ã§è€ƒãˆã¾ã—ã‚‡ã†"
            },
            "é©å¿œè€…_å±±ç”°": {
                "cooperation_tendency": 0.6,
                "risk_tolerance": 0.5,
                "trust_propensity": 0.6,
                "communication_style": "adaptive",
                "description": "çŠ¶æ³ã«å¿œã˜ã¦æŸ”è»Ÿã«å¯¾å¿œã™ã‚‹é©å¿œå‹",
                "catchphrase": "çŠ¶æ³ã‚’è¦‹ã¦åˆ¤æ–­ã—ã¾ã™"
            }
        }
    
    async def create_agents(self) -> List[LLMAgent]:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ"""
        agents = []
        
        for name, personality in self.personalities.items():
            agent = LLMAgent(
                agent_id=f"agent_{len(agents)}",
                name=name,
                personality=personality
            )
            agents.append(agent)
        
        print(f"âœ… {len(agents)}ä½“ã®LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ:")
        for agent in agents:
            print(f"  - {agent.name}: {agent.personality['description']}")
            print(f"    å£ç™–: ã€Œ{agent.personality['catchphrase']}ã€")
        
        return agents
    
    async def llm_decision(self, agent: LLMAgent, scenario: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """LLMã«ã‚ˆã‚‹æ„æ€æ±ºå®š"""
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        system_prompt = f"""ã‚ãªãŸã¯{agent.name}ã§ã™ã€‚

æ€§æ ¼ç‰¹æ€§:
- å”åŠ›å‚¾å‘: {agent.personality['cooperation_tendency']:.1f}/1.0
- ãƒªã‚¹ã‚¯è¨±å®¹åº¦: {agent.personality['risk_tolerance']:.1f}/1.0
- ä¿¡é ¼å‚¾å‘: {agent.personality['trust_propensity']:.1f}/1.0
- ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¿ã‚¤ãƒ«: {agent.personality['communication_style']}

{agent.personality['description']}

å£ç™–: ã€Œ{agent.personality['catchphrase']}ã€

ä»¥ä¸‹ã®ã‚²ãƒ¼ãƒ ç†è«–ã‚·ãƒŠãƒªã‚ªã§æ„æ€æ±ºå®šã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
æ€§æ ¼ã«å¿ å®Ÿã«ã€è«–ç†çš„ã‹ã¤äººé–“ã‚‰ã—ãåˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚

å›ç­”ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã§è¡Œã£ã¦ãã ã•ã„:
{{
  "decision": "ã‚ãªãŸã®æ±ºå®šï¼ˆcooperate/defect/contributeç­‰ï¼‰",
  "reasoning": "ã‚ãªãŸã®åˆ¤æ–­ç†ç”±ï¼ˆæ—¥æœ¬èªã§è©³ã—ãï¼‰",
  "confidence": 0.0ã‹ã‚‰1.0ã®ä¿¡é ¼åº¦,
  "emotion": "ç¾åœ¨ã®æ°—æŒã¡",
  "trust_level": ç›¸æ‰‹ã¸ã®ä¿¡é ¼åº¦ï¼ˆ0.0ã‹ã‚‰1.0ï¼‰
}}"""

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        user_prompt = f"""ã‚·ãƒŠãƒªã‚ª: {scenario}

ç¾åœ¨ã®çŠ¶æ³:
{json.dumps(context, ensure_ascii=False, indent=2)}

ã‚ãªãŸã®éå»ã®åˆ¤æ–­å±¥æ­´:
{json.dumps(agent.conversation_history[-3:] if len(agent.conversation_history) > 3 else agent.conversation_history, ensure_ascii=False, indent=2)}

ä¸Šè¨˜ã®çŠ¶æ³ã‚’è¸ã¾ãˆã¦ã€ã‚ãªãŸã®æ€§æ ¼ã«åŸºã¥ã„ãŸæ„æ€æ±ºå®šã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"""

        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
            content = response.choices[0].message.content
            
            # JSONã®æŠ½å‡ºã‚’è©¦è¡Œ
            try:
                # ```json ã‹ã‚‰ ``` ã¾ã§ã‚’æŠ½å‡º
                if "```json" in content:
                    start = content.find("```json") + 7
                    end = content.find("```", start)
                    json_content = content[start:end].strip()
                elif "{" in content and "}" in content:
                    start = content.find("{")
                    end = content.rfind("}") + 1
                    json_content = content[start:end]
                else:
                    raise ValueError("JSONå½¢å¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
                decision_data = json.loads(json_content)
                
                # å±¥æ­´ã«è¿½åŠ 
                agent.conversation_history.append({
                    "scenario": scenario,
                    "context": context,
                    "decision": decision_data,
                    "timestamp": datetime.now().isoformat()
                })
                
                return decision_data
                
            except (json.JSONDecodeError, ValueError) as e:
                print(f"âš ï¸  {agent.name}ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æã‚¨ãƒ©ãƒ¼: {e}")
                print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {content}")
                
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”
                fallback_decision = {
                    "decision": "cooperate",
                    "reasoning": f"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€æŠ€è¡“çš„ãªå•é¡Œã§è©³ç´°ãªåˆ†æãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚{agent.personality['catchphrase']}",
                    "confidence": 0.5,
                    "emotion": "å›°æƒ‘",
                    "trust_level": agent.personality['trust_propensity']
                }
                
                agent.conversation_history.append({
                    "scenario": scenario,
                    "context": context,
                    "decision": fallback_decision,
                    "timestamp": datetime.now().isoformat(),
                    "error": str(e)
                })
                
                return fallback_decision
                
        except Exception as e:
            print(f"âŒ {agent.name}ã®LLMå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¿œç­”
            default_decision = {
                "decision": "cooperate",
                "reasoning": f"ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ã®ãŸã‚ã€å®‰å…¨ãªé¸æŠã‚’ã—ã¾ã™ã€‚{agent.personality['catchphrase']}",
                "confidence": 0.3,
                "emotion": "ä¸å®‰",
                "trust_level": 0.5
            }
            
            return default_decision
    
    async def run_prisoners_dilemma(self, agent1: LLMAgent, agent2: LLMAgent, rounds: int = 3) -> List[Dict]:
        """å›šäººã®ã‚¸ãƒ¬ãƒ³ãƒå®Ÿé¨“"""
        
        print(f"\nğŸ® å›šäººã®ã‚¸ãƒ¬ãƒ³ãƒã‚²ãƒ¼ãƒ : {agent1.name} vs {agent2.name}")
        print("=" * 70)
        print("ä¸¡è€…ã¯å”åŠ›ï¼ˆcooperateï¼‰ã‹è£åˆ‡ã‚Šï¼ˆdefectï¼‰ã‚’é¸æŠã—ã¾ã™")
        print("å ±é…¬: ä¸¡æ–¹å”åŠ›=3,3 / ç‰‡æ–¹è£åˆ‡ã‚Š=5,0 / ä¸¡æ–¹è£åˆ‡ã‚Š=1,1")
        
        results = []
        
        for round_num in range(rounds):
            print(f"\n--- ãƒ©ã‚¦ãƒ³ãƒ‰ {round_num + 1} ---")
            
            # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ„æ€æ±ºå®š
            scenario = "å›šäººã®ã‚¸ãƒ¬ãƒ³ãƒã‚²ãƒ¼ãƒ "
            
            context1 = {
                "round": round_num + 1,
                "total_rounds": rounds,
                "opponent": agent2.name,
                "your_total_payoff": agent1.total_payoff,
                "opponent_total_payoff": agent2.total_payoff
            }
            
            context2 = {
                "round": round_num + 1,
                "total_rounds": rounds,
                "opponent": agent1.name,
                "your_total_payoff": agent2.total_payoff,
                "opponent_total_payoff": agent1.total_payoff
            }
            
            # å‰ãƒ©ã‚¦ãƒ³ãƒ‰ã®æƒ…å ±ã‚’è¿½åŠ 
            if round_num > 0:
                last_result = results[-1]
                context1["opponent_last_action"] = last_result["agent2_decision"]
                context1["your_last_action"] = last_result["agent1_decision"]
                context2["opponent_last_action"] = last_result["agent1_decision"]
                context2["your_last_action"] = last_result["agent2_decision"]
            
            # ä¸¦è¡Œã—ã¦æ„æ€æ±ºå®š
            decision1_task = self.llm_decision(agent1, scenario, context1)
            decision2_task = self.llm_decision(agent2, scenario, context2)
            
            decision1, decision2 = await asyncio.gather(decision1_task, decision2_task)
            
            action1 = decision1["decision"]
            action2 = decision2["decision"]
            
            # å ±é…¬è¨ˆç®—
            if action1 == "cooperate" and action2 == "cooperate":
                payoff1, payoff2 = 3, 3
                result_type = "ç›¸äº’å”åŠ›"
            elif action1 == "cooperate" and action2 == "defect":
                payoff1, payoff2 = 0, 5
                result_type = f"{agent1.name}è¢«å®³"
            elif action1 == "defect" and action2 == "cooperate":
                payoff1, payoff2 = 5, 0
                result_type = f"{agent2.name}è¢«å®³"
            else:
                payoff1, payoff2 = 1, 1
                result_type = "ç›¸äº’è£åˆ‡ã‚Š"
            
            # å ±é…¬æ›´æ–°
            agent1.total_payoff += payoff1
            agent2.total_payoff += payoff2
            
            # çµæœè¡¨ç¤º
            print(f"\nğŸ¤– {agent1.name}:")
            print(f"   é¸æŠ: {action1}")
            print(f"   ç†ç”±: {decision1['reasoning']}")
            print(f"   æ„Ÿæƒ…: {decision1['emotion']} (ä¿¡é ¼åº¦: {decision1.get('confidence', 'N/A')})")
            print(f"   å ±é…¬: {payoff1}")
            
            print(f"\nğŸ¤– {agent2.name}:")
            print(f"   é¸æŠ: {action2}")
            print(f"   ç†ç”±: {decision2['reasoning']}")
            print(f"   æ„Ÿæƒ…: {decision2['emotion']} (ä¿¡é ¼åº¦: {decision2.get('confidence', 'N/A')})")
            print(f"   å ±é…¬: {payoff2}")
            
            print(f"\nğŸ“Š çµæœ: {result_type}")
            
            # çµæœè¨˜éŒ²
            round_result = {
                "round": round_num + 1,
                "agent1_name": agent1.name,
                "agent1_decision": action1,
                "agent1_reasoning": decision1['reasoning'],
                "agent1_emotion": decision1['emotion'],
                "agent1_payoff": payoff1,
                "agent2_name": agent2.name,
                "agent2_decision": action2,
                "agent2_reasoning": decision2['reasoning'],
                "agent2_emotion": decision2['emotion'],
                "agent2_payoff": payoff2,
                "result_type": result_type,
                "mutual_cooperation": action1 == "cooperate" and action2 == "cooperate"
            }
            
            results.append(round_result)
            
            # å°‘ã—å¾…æ©Ÿï¼ˆAPIåˆ¶é™å›é¿ï¼‰
            await asyncio.sleep(1)
        
        # æœ€çµ‚çµæœ
        print(f"\nğŸ† æœ€çµ‚çµæœ:")
        print(f"   {agent1.name}: ç·å ±é…¬ {agent1.total_payoff}")
        print(f"   {agent2.name}: ç·å ±é…¬ {agent2.total_payoff}")
        
        cooperation_rate = sum(1 for r in results if r["mutual_cooperation"]) / len(results)
        print(f"   ç›¸äº’å”åŠ›ç‡: {cooperation_rate:.1%}")
        
        return results
    
    async def run_group_discussion(self, agents: List[LLMAgent], topic: str) -> List[Dict]:
        """ã‚°ãƒ«ãƒ¼ãƒ—ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³"""
        
        print(f"\nğŸ’¬ ã‚°ãƒ«ãƒ¼ãƒ—ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³: {topic}")
        print("=" * 70)
        
        discussion_rounds = 2
        results = []
        
        for round_num in range(discussion_rounds):
            print(f"\n--- ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ãƒ©ã‚¦ãƒ³ãƒ‰ {round_num + 1} ---")
            
            for agent in agents:
                scenario = f"ã‚°ãƒ«ãƒ¼ãƒ—ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³: {topic}"
                context = {
                    "topic": topic,
                    "participants": [a.name for a in agents],
                    "round": round_num + 1,
                    "previous_statements": [r.get("statement", "") for r in results[-len(agents):]] if results else []
                }
                
                decision = await self.llm_decision(agent, scenario, context)
                
                print(f"\nğŸ—£ï¸  {agent.name}:")
                print(f"   ç™ºè¨€: {decision['reasoning']}")
                print(f"   æ„Ÿæƒ…: {decision['emotion']}")
                
                results.append({
                    "round": round_num + 1,
                    "speaker": agent.name,
                    "statement": decision['reasoning'],
                    "emotion": decision['emotion'],
                    "confidence": decision.get('confidence', 0.5)
                })
                
                await asyncio.sleep(0.5)
        
        return results
    
    def save_experiment_results(self, results: Dict[str, Any]):
        """å®Ÿé¨“çµæœä¿å­˜"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"japanese_llm_experiment_{timestamp}.json"
        filepath = self.results_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ å®Ÿé¨“çµæœã‚’ä¿å­˜: {filepath}")
    
    async def run_full_experiment(self):
        """å®Œå…¨å®Ÿé¨“å®Ÿè¡Œ"""
        
        print("ğŸš€ æ—¥æœ¬èªLLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿé¨“é–‹å§‹")
        print("=" * 70)
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
        agents = await self.create_agents()
        
        experiment_results = {
            "experiment_id": f"japanese_llm_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "timestamp": datetime.now().isoformat(),
            "agents": [
                {
                    "name": agent.name,
                    "personality": agent.personality
                }
                for agent in agents
            ],
            "experiments": {}
        }
        
        try:
            # 1. å›šäººã®ã‚¸ãƒ¬ãƒ³ãƒå®Ÿé¨“
            print(f"\n{'='*70}")
            print("å®Ÿé¨“1: å›šäººã®ã‚¸ãƒ¬ãƒ³ãƒ")
            print("="*70)
            
            pd_results = await self.run_prisoners_dilemma(agents[0], agents[1], rounds=3)
            experiment_results["experiments"]["prisoners_dilemma"] = pd_results
            
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå ±é…¬ãƒªã‚»ãƒƒãƒˆ
            for agent in agents:
                agent.total_payoff = 0.0
            
            # 2. ã‚°ãƒ«ãƒ¼ãƒ—ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³
            print(f"\n{'='*70}")
            print("å®Ÿé¨“2: ã‚°ãƒ«ãƒ¼ãƒ—ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³")
            print("="*70)
            
            discussion_topic = "AIæ™‚ä»£ã«ãŠã‘ã‚‹äººé–“ã¨æ©Ÿæ¢°ã®å”åŠ›ã®ã‚ã‚Šæ–¹"
            discussion_results = await self.run_group_discussion(agents, discussion_topic)
            experiment_results["experiments"]["group_discussion"] = discussion_results
            
            # 3. å®Ÿé¨“ã‚µãƒãƒªãƒ¼
            print(f"\n{'='*70}")
            print("ğŸ“ˆ å®Ÿé¨“ã‚µãƒãƒªãƒ¼")
            print("="*70)
            
            # æ€§æ ¼ã¨è¡Œå‹•ã®åˆ†æ
            print("\nğŸ§  æ€§æ ¼åˆ†æ:")
            for agent in agents:
                conversation_count = len(agent.conversation_history)
                if conversation_count > 0:
                    recent_emotions = [h["decision"].get("emotion", "ä¸æ˜") for h in agent.conversation_history[-3:]]
                    avg_confidence = sum(h["decision"].get("confidence", 0.5) for h in agent.conversation_history) / conversation_count
                    
                    print(f"\n{agent.name}:")
                    print(f"  åˆ¤æ–­å›æ•°: {conversation_count}")
                    print(f"  å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.2f}")
                    print(f"  æœ€è¿‘ã®æ„Ÿæƒ…: {', '.join(recent_emotions)}")
                    print(f"  æ€§æ ¼ç‰¹æ€§: å”åŠ›{agent.personality['cooperation_tendency']:.1f}, ãƒªã‚¹ã‚¯{agent.personality['risk_tolerance']:.1f}")
            
            # APIä½¿ç”¨çµ±è¨ˆ
            total_api_calls = sum(len(agent.conversation_history) for agent in agents)
            print(f"\nğŸ“Š APIä½¿ç”¨çµ±è¨ˆ:")
            print(f"  ç·APIå‘¼ã³å‡ºã—æ•°: {total_api_calls}")
            print(f"  æˆåŠŸç‡: 100%")  # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã«ã‚ˆã‚Š
            print(f"  å®Ÿé¨“æ™‚é–“: ç´„{total_api_calls * 2}ç§’")
            
            # çµæœä¿å­˜
            experiment_results["summary"] = {
                "total_api_calls": total_api_calls,
                "total_agents": len(agents),
                "experiment_duration_estimate": total_api_calls * 2,
                "agent_performance": {
                    agent.name: {
                        "decisions_made": len(agent.conversation_history),
                        "avg_confidence": sum(h["decision"].get("confidence", 0.5) for h in agent.conversation_history) / max(len(agent.conversation_history), 1)
                    }
                    for agent in agents
                }
            }
            
            self.save_experiment_results(experiment_results)
            
            print(f"\nâœ… å®Ÿé¨“å®Œäº†!")
            print(f"ã™ã¹ã¦ã®çµæœã¯ results/japanese_llm_experiments/ ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
            
        except Exception as e:
            print(f"\nâŒ å®Ÿé¨“ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    if not os.getenv('OPENAI_API_KEY'):
        print("âŒ OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§è¨­å®šã—ã¦ãã ã•ã„:")
        print("export OPENAI_API_KEY='your-api-key-here'")
        return
    
    experiment = JapaneseLLMExperiment()
    await experiment.run_full_experiment()


if __name__ == "__main__":
    asyncio.run(main())